{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hello World with cuDF and Streamz\n",
    "\n",
    "This notebook demonstrates use of cuDF to perform streaming word-count using a small portion of the [Streamz API](https://streamz.readthedocs.io/en/latest/).\n",
    "\n",
    "This notebook was tested using the `rapidsai/rapidsai-dev-nightly:0.10-cuda10.0-devel-ubuntu18.04-py3.7` container from [DockerHub](https://hub.docker.com/r/rapidsai/rapidsai-nightly) and run on the NVIDIA GV100 GPU. Please be aware that your system may be different and you may need to modify the code or install packages to run the below examples. \n",
    "\n",
    "If you think you have found a bug or an error, please file an issue here:  https://github.com/rapidsai/notebooks-contrib/issues\n",
    "\n",
    "First, make sure you have installed the [Streamz](https://github.com/python-streamz/streamz) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c conda-forge -y streamz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "First import the required packages. We'll be programmatically generating data and process in streaming batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from streamz import Stream\n",
    "import cudf, json\n",
    "\n",
    "# create a list of static messages\n",
    "messages = [\n",
    "    {'msg': 'Hello, World!'},\n",
    "    {'msg': 'hi, world!'},\n",
    "    {'msg': 'hey world'},\n",
    "    {'msg': 'Hi'}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define A Function to Run Per Batch\n",
    "\n",
    "While some streaming systems deal with single events at a time, using GPUs to run a per-event process is not ideal due to the high latency of PCI-E memory transfers and kernel call overhead.\n",
    "\n",
    "For our example, we'll focus on processing batches at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to run per batch\n",
    "def process_on_gpu(messages):\n",
    "    # read the batch of messages into a GPU DataFrame\n",
    "    df = cudf.read_json('\\n'.join(messages), lines=True)\n",
    "    \n",
    "    # split each line into columns, one per word\n",
    "    tmp = df['msg'].str.split()\n",
    "    \n",
    "    # combine all word columns into a single Series\n",
    "    words = tmp[tmp.columns[0]]\n",
    "    for word in tmp.columns[1:]:\n",
    "        words = words.append(tmp[word])\n",
    "    \n",
    "    # remove punctuation, lower-case\n",
    "    words = words.str.fillna('').replace(',', '').replace('!', '').str.lower()\n",
    "\n",
    "    # compute and return word counts for the batch\n",
    "    return str(words.groupby(words).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the Stream and Emit Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = Stream()\n",
    "\n",
    "# GPUs like to process sizable chunks of data at once\n",
    "# source.partition(n) sends n events at a time to downstream functions\n",
    "source.partition(10).map(process_on_gpu).sink(print)\n",
    "\n",
    "# with 30 events partitioned by 10 events per group will give 3 \"batches\"\n",
    "n_messages = 30\n",
    "for idx in range(0, n_messages):\n",
    "    source.emit(json.dumps(messages[idx % len(messages)]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
