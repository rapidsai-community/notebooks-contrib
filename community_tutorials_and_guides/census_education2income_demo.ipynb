{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Census Notebook\n",
    "**Authorship**<br />\n",
    "Original Author: Taurean Dyer<br />\n",
    "Last Edit: Taurean Dyer, 9/26/2019<br />\n",
    "\n",
    "**Test System Specs**<br />\n",
    "Test System Hardware: GV100<br />\n",
    "Test System Software: Ubuntu 18.04<br />\n",
    "RAPIDS Version: 0.10.0a - Docker Install<br />\n",
    "Driver: 410.79<br />\n",
    "CUDA: 10.0<br />\n",
    "\n",
    "\n",
    "**Known Working Systems**<br />\n",
    "RAPIDS Versions:0.8, 0.9, 0.10\n",
    "\n",
    "# Intro\n",
    "Held every 10 years, the US census gives a detailed snapshot in time about the makeup of the country.  The last census in 2010 surveyed nearly 309 million people.  IPUMS.org provides researchers an open source data set with 1% to 10% of the census data set.  In this notebook, we want to see how education affects total income earned in the US based on data from each census from the 1970 to 2010 and see if we can predict some results if the census was held today, according to the national average.  We will go through the ETL, training the model, and then testing the prediction.  We'll make every effort to get as balanced of a dataset as we can.  We'll also pull some extra variables to allow for further self-exploration of gender based education and income breakdowns.  On a single Titan RTX, you can run the whole notebook workflow on the 4GB dataset of 14 million rows by 44 columns in less than 3 minutes.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's begin!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cuml\n",
    "import cudf\n",
    "import dask_cudf\n",
    "import sys\n",
    "import os\n",
    "from pprint import pprint\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get your data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:33355</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>1</li>\n",
       "  <li><b>Memory: </b>16.48 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:33355' processes=1 threads=1, memory=16.48 GB>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "import time\n",
    "\n",
    "from dask.distributed import Client, wait\n",
    "from dask_cuda import LocalCUDACluster\n",
    "\n",
    "cluster = LocalCUDACluster()\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ipums dataset is in our S3 bucket and zipped.  \n",
    "1. We'll need to create a folder for our data in the `/data` folder\n",
    "1. Download the zipped data into that folder from S3\n",
    "1. Load the zipped data quickly into cudf using it's read_csv() parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating census data directory\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../data/census/'\n",
    "if not os.path.exists(data_dir):\n",
    "    print('creating census data directory')\n",
    "    os.system('mkdir ../data/census/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://rapidsai-data.s3.us-east-2.amazonaws.com/datasets/ipums_education2income_1970-2010.csv.gz to ../data/census/ipums_education2income_1970-2010.csv.gz\n"
     ]
    }
   ],
   "source": [
    "# download the IPUMS dataset\n",
    "base_url = 'https://rapidsai-data.s3.us-east-2.amazonaws.com/datasets/'\n",
    "fn = 'ipums_education2income_1970-2010.csv.gz'\n",
    "if not os.path.isfile(data_dir+fn):\n",
    "    print(f'Downloading {base_url+fn} to {data_dir+fn}')\n",
    "    urllib.request.urlretrieve(base_url+fn, data_dir+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(cached = data_dir+fn):\n",
    "    if os.path.exists(cached):\n",
    "        print('use ipums data')\n",
    "        X = cudf.read_csv(cached, compression='infer')\n",
    "    else:\n",
    "        print(\"No data found!  Please check your that your data directory is ../../data/census/ and that you downloaded the data.  If you did, please delete the `../../../data/census/` directory and try the above 2 cells again\")\n",
    "        X = null\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use ipums data\n",
      "data (100, 45)\n"
     ]
    }
   ],
   "source": [
    "df = load_data(data_dir+fn)\n",
    "# limit\n",
    "df = df[0:100]\n",
    "print('data',df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   YEAR  DATANUM  SERIAL  CBSERIAL  HHWT  CPI99  GQ  QGQ  PERNUM  PERWT  ...  \\\n",
      "0  1970        2       1       NaN   100   4.54   1  0.0       1    100  ...   \n",
      "1  1970        2       1       NaN   100   4.54   1  0.0       2    100  ...   \n",
      "2  1970        2       2       NaN   100   4.54   1  0.0       1    100  ...   \n",
      "3  1970        2       2       NaN   100   4.54   1  0.0       2    100  ...   \n",
      "4  1970        2       4       NaN   100   4.54   1  0.0       1    100  ...   \n",
      "\n",
      "   EDUCD_POP  EDUCD_SP  EDUCD_MOM2  EDUCD_POP2  INCTOT_HEAD  INCTOT_MOM  \\\n",
      "0        NaN      30.0         NaN         NaN      12450.0         NaN   \n",
      "1        NaN      60.0         NaN         NaN      12450.0         NaN   \n",
      "2        NaN      60.0         NaN         NaN       9050.0         NaN   \n",
      "3        NaN      70.0         NaN         NaN       9050.0         NaN   \n",
      "4        NaN      23.0         NaN         NaN       7450.0         NaN   \n",
      "\n",
      "   INCTOT_POP  INCTOT_SP  INCTOT_MOM2  INCTOT_POP2  \n",
      "0         NaN     3450.0          NaN          NaN  \n",
      "1         NaN    12450.0          NaN          NaN  \n",
      "2         NaN        0.0          NaN          NaN  \n",
      "3         NaN     9050.0          NaN          NaN  \n",
      "4         NaN      650.0          NaN          NaN  \n",
      "\n",
      "[5 rows x 45 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head(5).to_pandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YEAR             int64\n",
       "DATANUM          int64\n",
       "SERIAL           int64\n",
       "CBSERIAL       float64\n",
       "HHWT             int64\n",
       "CPI99          float64\n",
       "GQ               int64\n",
       "QGQ            float64\n",
       "PERNUM           int64\n",
       "PERWT            int64\n",
       "SEX              int64\n",
       "AGE              int64\n",
       "EDUC             int64\n",
       "EDUCD            int64\n",
       "INCTOT           int64\n",
       "SEX_HEAD       float64\n",
       "SEX_MOM        float64\n",
       "SEX_POP        float64\n",
       "SEX_SP         float64\n",
       "SEX_MOM2       float64\n",
       "SEX_POP2       float64\n",
       "AGE_HEAD       float64\n",
       "AGE_MOM        float64\n",
       "AGE_POP        float64\n",
       "AGE_SP         float64\n",
       "AGE_MOM2       float64\n",
       "AGE_POP2       float64\n",
       "EDUC_HEAD      float64\n",
       "EDUC_MOM       float64\n",
       "EDUC_POP       float64\n",
       "EDUC_SP        float64\n",
       "EDUC_MOM2      float64\n",
       "EDUC_POP2      float64\n",
       "EDUCD_HEAD     float64\n",
       "EDUCD_MOM      float64\n",
       "EDUCD_POP      float64\n",
       "EDUCD_SP       float64\n",
       "EDUCD_MOM2     float64\n",
       "EDUCD_POP2     float64\n",
       "INCTOT_HEAD    float64\n",
       "INCTOT_MOM     float64\n",
       "INCTOT_POP     float64\n",
       "INCTOT_SP      float64\n",
       "INCTOT_MOM2    float64\n",
       "INCTOT_POP2    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1970    100\n",
      "Name: YEAR, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "original_counts = df.YEAR.value_counts()\n",
    "print(original_counts) ### Remember these numbers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Income data\n",
    "First, let's focus on cleaning out the bad values for Total Income `INCTOT`. First, let's see if there are an `N/A` values, as when we did `head()`, we saw some in other columns, like CBSERIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['INCTOT_NA'] = df['INCTOT'].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    100\n",
      "Name: INCTOT_NA, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "print(df.INCTOT_NA.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, great, there are no `N/A`s...or are there?  Let's drop `INCTOT_NA` and see what our value counts look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999999    21\n",
      "0          14\n",
      "250         4\n",
      "4050        3\n",
      "5050        3\n",
      "350         3\n",
      "2050        3\n",
      "9050        2\n",
      "4850        2\n",
      "650         2\n",
      "2150        2\n",
      "1250        2\n",
      "22150       1\n",
      "5650        1\n",
      "17850       1\n",
      "1050        1\n",
      "11250       1\n",
      "5550        1\n",
      "50          1\n",
      "16850       1\n",
      "11150       1\n",
      "4350        1\n",
      "7450        1\n",
      "13350       1\n",
      "6950        1\n",
      "25050       1\n",
      "1850        1\n",
      "2450        1\n",
      "17150       1\n",
      "6150        1\n",
      "12450       1\n",
      "11450       1\n",
      "4550        1\n",
      "50000       1\n",
      "550         1\n",
      "8850        1\n",
      "8050        1\n",
      "6050        1\n",
      "19350       1\n",
      "2950        1\n",
      "150         1\n",
      "1150        1\n",
      "2750        1\n",
      "7150        1\n",
      "15050       1\n",
      "7750        1\n",
      "3450        1\n",
      "5350        1\n",
      "7050        1\n",
      "950         1\n",
      "12050       1\n",
      "Name: INCTOT, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "df=df.drop('INCTOT_NA', axis=1)\n",
    "print(df.INCTOT.value_counts().to_pandas())  ### Wow, look how many people in America make $10,000,000!  Wait a minutes... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not that many people make $10M a year. Checking https://usa.ipums.org/usa-action/variables/INCTOT#codes_section, `9999999`is INCTOT's code for `N/A`.  That was why when we ran `isna`, RAPIDS won't find any.  Let's first create a new dataframe that is only NA values, then let's pull those encoded `N/A`s out of our working dataframe!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data (100, 45)\n"
     ]
    }
   ],
   "source": [
    "print('data',df.shape)\n",
    "tdf = df.query('INCTOT == 9999999')\n",
    "df = df.query('INCTOT != 9999999')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working data (79, 45)\n",
      "junk count data (21, 45)\n"
     ]
    }
   ],
   "source": [
    "print('working data',df.shape)\n",
    "print('junk count data',tdf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're down by nearly 1/4 of our original dataset size.  For the curious, now we should be able to get accurate Total Income data, by year, not taking into account inflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YEAR\n",
      "1970    5503.797468\n",
      "Name: INCTOT, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby('YEAR')['INCTOT'].mean()) # without that cleanup, the average would have bene in the millions...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize Income for inflation\n",
    "Now that we have reduced our dataframe to a baseline clean data to answer our question, we should normalize the amounts for inflation.  `CPI99`is the value that IPUMS uses to contian the inflation factor.  All we have to do is multipy by year.  Let's see how that changes the Total Income values from just above!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YEAR\n",
      "1970    4.54\n",
      "Name: CPI99, dtype: float64\n",
      "YEAR\n",
      "1970    24987.240506\n",
      "Name: INCTOT, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby('YEAR')['CPI99'].mean()) ## it just returns the CPI99\n",
    "df['INCTOT'] = df['INCTOT'] * df['CPI99']\n",
    "print(df.groupby('YEAR')['INCTOT'].mean()) ## let's see what we got!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Education Data\n",
    "Okay, great!  Now we have income cleaned up, it should also have cleaned much of our next sets of values of interes, namely Education and Education Detailed.  However, there are still some `N/A`s in key variables to worry about, which can cause problmes later.  Let's create a list of them..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "suspect = ['CBSERIAL','EDUC', 'EDUCD', 'EDUC_HEAD', 'EDUC_POP', 'EDUC_MOM','EDUCD_MOM2','EDUCD_POP2', 'INCTOT_MOM','INCTOT_POP','INCTOT_MOM2','INCTOT_POP2', 'INCTOT_HEAD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBSERIAL -1.0    79\n",
      "Name: CBSERIAL, dtype: int32\n",
      "EDUC 6     22\n",
      "2     15\n",
      "10     8\n",
      "3      7\n",
      "4      7\n",
      "11     6\n",
      "8      5\n",
      "7      4\n",
      "1      3\n",
      "5      1\n",
      "9      1\n",
      "Name: EDUC, dtype: int32\n",
      "EDUCD 60     20\n",
      "26      9\n",
      "100     8\n",
      "30      7\n",
      "40      7\n",
      "111     6\n",
      "80      5\n",
      "70      4\n",
      "25      3\n",
      "23      2\n",
      "14      2\n",
      "65      2\n",
      "90      1\n",
      "50      1\n",
      "22      1\n",
      "17      1\n",
      "Name: EDUCD, dtype: int32\n",
      "EDUC_HEAD  6.0     13\n",
      " 11.0    12\n",
      " 8.0     10\n",
      " 2.0     10\n",
      " 7.0      9\n",
      " 10.0     9\n",
      " 4.0      6\n",
      " 1.0      4\n",
      " 3.0      3\n",
      " 5.0      2\n",
      "-1.0      1\n",
      "Name: EDUC_HEAD, dtype: int32\n",
      "EDUC_POP -1.0     68\n",
      " 8.0      3\n",
      " 7.0      3\n",
      " 2.0      2\n",
      " 11.0     2\n",
      " 10.0     1\n",
      "Name: EDUC_POP, dtype: int32\n",
      "EDUC_MOM -1.0     64\n",
      " 6.0      8\n",
      " 10.0     3\n",
      " 3.0      2\n",
      " 7.0      1\n",
      " 2.0      1\n",
      "Name: EDUC_MOM, dtype: int32\n",
      "EDUCD_MOM2 -1.0    79\n",
      "Name: EDUCD_MOM2, dtype: int32\n",
      "EDUCD_POP2 -1.0    79\n",
      "Name: EDUCD_POP2, dtype: int32\n",
      "INCTOT_MOM -1.0       64\n",
      " 0.0        4\n",
      " 650.0      3\n",
      " 2050.0     2\n",
      " 4850.0     2\n",
      " 1150.0     2\n",
      " 7750.0     1\n",
      " 1250.0     1\n",
      "Name: INCTOT_MOM, dtype: int32\n",
      "INCTOT_POP -1.0        68\n",
      " 12050.0     3\n",
      " 50000.0     2\n",
      " 8850.0      2\n",
      " 7050.0      2\n",
      " 17850.0     1\n",
      " 13350.0     1\n",
      "Name: INCTOT_POP, dtype: int32\n",
      "INCTOT_MOM2 -1.0    79\n",
      "Name: INCTOT_MOM2, dtype: int32\n",
      "INCTOT_POP2 -1.0    79\n",
      "Name: INCTOT_POP2, dtype: int32\n",
      "INCTOT_HEAD  12050.0    5\n",
      " 50000.0    4\n",
      " 9050.0     4\n",
      " 8850.0     4\n",
      " 5050.0     4\n",
      " 7050.0     4\n",
      " 11250.0    3\n",
      " 17850.0    3\n",
      " 13350.0    3\n",
      " 8050.0     3\n",
      " 2150.0     3\n",
      " 25050.0    2\n",
      " 4850.0     2\n",
      " 250.0      2\n",
      " 4050.0     2\n",
      " 22150.0    2\n",
      " 6150.0     2\n",
      " 7450.0     2\n",
      " 2450.0     2\n",
      " 7750.0     2\n",
      " 11450.0    2\n",
      " 11150.0    2\n",
      " 6950.0     2\n",
      " 15050.0    2\n",
      " 19350.0    2\n",
      " 12450.0    2\n",
      " 16850.0    2\n",
      " 6050.0     2\n",
      " 2050.0     1\n",
      " 0.0        1\n",
      "-1.0        1\n",
      " 1250.0     1\n",
      " 17150.0    1\n",
      "Name: INCTOT_HEAD, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(suspect)):\n",
    "    df[suspect[i]] = df[suspect[i]].fillna(-1)\n",
    "    print(suspect[i], df[suspect[i]].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get drop any rows of any `-1`s in Education and Education Detailed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDUC\n",
      "EDUCD\n"
     ]
    }
   ],
   "source": [
    "totincome = ['EDUC','EDUCD']\n",
    "for i in range(0, len(totincome)):\n",
    "    query = totincome[i] + ' != -1'\n",
    "    df = df.query(query)\n",
    "    print(totincome[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79, 45)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>DATANUM</th>\n",
       "      <th>SERIAL</th>\n",
       "      <th>CBSERIAL</th>\n",
       "      <th>HHWT</th>\n",
       "      <th>CPI99</th>\n",
       "      <th>GQ</th>\n",
       "      <th>QGQ</th>\n",
       "      <th>PERNUM</th>\n",
       "      <th>PERWT</th>\n",
       "      <th>...</th>\n",
       "      <th>EDUCD_POP</th>\n",
       "      <th>EDUCD_SP</th>\n",
       "      <th>EDUCD_MOM2</th>\n",
       "      <th>EDUCD_POP2</th>\n",
       "      <th>INCTOT_HEAD</th>\n",
       "      <th>INCTOT_MOM</th>\n",
       "      <th>INCTOT_POP</th>\n",
       "      <th>INCTOT_SP</th>\n",
       "      <th>INCTOT_MOM2</th>\n",
       "      <th>INCTOT_POP2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1970</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>4.54</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>12450.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1970</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>4.54</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>12450.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>12450.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1970</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>4.54</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>9050.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1970</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>4.54</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>9050.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>9050.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1970</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>4.54</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>7450.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR  DATANUM  SERIAL  CBSERIAL  HHWT  CPI99  GQ  QGQ  PERNUM  PERWT  ...  \\\n",
       "0  1970        2       1      -1.0   100   4.54   1  0.0       1    100  ...   \n",
       "1  1970        2       1      -1.0   100   4.54   1  0.0       2    100  ...   \n",
       "2  1970        2       2      -1.0   100   4.54   1  0.0       1    100  ...   \n",
       "3  1970        2       2      -1.0   100   4.54   1  0.0       2    100  ...   \n",
       "4  1970        2       4      -1.0   100   4.54   1  0.0       1    100  ...   \n",
       "\n",
       "   EDUCD_POP  EDUCD_SP  EDUCD_MOM2  EDUCD_POP2  INCTOT_HEAD  INCTOT_MOM  \\\n",
       "0        NaN      30.0        -1.0        -1.0      12450.0        -1.0   \n",
       "1        NaN      60.0        -1.0        -1.0      12450.0        -1.0   \n",
       "2        NaN      60.0        -1.0        -1.0       9050.0        -1.0   \n",
       "3        NaN      70.0        -1.0        -1.0       9050.0        -1.0   \n",
       "4        NaN      23.0        -1.0        -1.0       7450.0        -1.0   \n",
       "\n",
       "   INCTOT_POP  INCTOT_SP  INCTOT_MOM2  INCTOT_POP2  \n",
       "0        -1.0     3450.0         -1.0         -1.0  \n",
       "1        -1.0    12450.0         -1.0         -1.0  \n",
       "2        -1.0        0.0         -1.0         -1.0  \n",
       "3        -1.0     9050.0         -1.0         -1.0  \n",
       "4        -1.0      650.0         -1.0         -1.0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head().to_pandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, the good news is that we lost no further rows, start to normalize the data so when we do our OLS, one year doesn't unfairly dominate the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the Data\n",
    "The in the last step, need to keep our data at about the same ratio as we when started (1% of the population), with the exception of 1980, which was a 5% and needs to be reduced.  This is why we kept the temp dataframe `tdf` - to get the counts per year.   we will find out just how many have to realize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working data: \n",
      " 1970    79\n",
      "Name: YEAR, dtype: int32\n",
      "junk count data: \n",
      " 1970    21\n",
      "Name: YEAR, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "print('Working data: \\n', df.YEAR.value_counts())\n",
    "print('junk count data: \\n', tdf.YEAR.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, so that we can do MSE, let's make all the dtypes the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YEAR             int64\n",
       "DATANUM          int64\n",
       "SERIAL           int64\n",
       "CBSERIAL       float64\n",
       "HHWT             int64\n",
       "CPI99          float64\n",
       "GQ               int64\n",
       "QGQ            float64\n",
       "PERNUM           int64\n",
       "PERWT            int64\n",
       "SEX              int64\n",
       "AGE              int64\n",
       "EDUC             int64\n",
       "EDUCD            int64\n",
       "INCTOT         float64\n",
       "SEX_HEAD       float64\n",
       "SEX_MOM        float64\n",
       "SEX_POP        float64\n",
       "SEX_SP         float64\n",
       "SEX_MOM2       float64\n",
       "SEX_POP2       float64\n",
       "AGE_HEAD       float64\n",
       "AGE_MOM        float64\n",
       "AGE_POP        float64\n",
       "AGE_SP         float64\n",
       "AGE_MOM2       float64\n",
       "AGE_POP2       float64\n",
       "EDUC_HEAD      float64\n",
       "EDUC_MOM       float64\n",
       "EDUC_POP       float64\n",
       "EDUC_SP        float64\n",
       "EDUC_MOM2      float64\n",
       "EDUC_POP2      float64\n",
       "EDUCD_HEAD     float64\n",
       "EDUCD_MOM      float64\n",
       "EDUCD_POP      float64\n",
       "EDUCD_SP       float64\n",
       "EDUCD_MOM2     float64\n",
       "EDUCD_POP2     float64\n",
       "INCTOT_HEAD    float64\n",
       "INCTOT_MOM     float64\n",
       "INCTOT_POP     float64\n",
       "INCTOT_SP      float64\n",
       "INCTOT_MOM2    float64\n",
       "INCTOT_POP2    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YEAR 1970    79\n",
      "Name: YEAR, dtype: int32\n",
      "DATANUM 2    79\n",
      "Name: DATANUM, dtype: int32\n",
      "SERIAL 18    5\n",
      "14    4\n",
      "37    4\n",
      "31    4\n",
      "32    3\n",
      "39    3\n",
      "16    3\n",
      "10    3\n",
      "5     2\n",
      "26    2\n",
      "25    2\n",
      "20    2\n",
      "38    2\n",
      "13    2\n",
      "21    2\n",
      "4     2\n",
      "36    2\n",
      "1     2\n",
      "19    2\n",
      "33    2\n",
      "22    2\n",
      "7     2\n",
      "17    2\n",
      "9     2\n",
      "27    2\n",
      "2     2\n",
      "15    2\n",
      "34    2\n",
      "29    2\n",
      "23    1\n",
      "28    1\n",
      "6     1\n",
      "30    1\n",
      "24    1\n",
      "35    1\n",
      "11    1\n",
      "8     1\n",
      "Name: SERIAL, dtype: int32\n",
      "CBSERIAL -1.0    79\n",
      "Name: CBSERIAL, dtype: int32\n",
      "HHWT 100    79\n",
      "Name: HHWT, dtype: int32\n",
      "GQ 1    78\n",
      "3     1\n",
      "Name: GQ, dtype: int32\n",
      "PERNUM 1    37\n",
      "2    29\n",
      "3     8\n",
      "4     4\n",
      "5     1\n",
      "Name: PERNUM, dtype: int32\n",
      "SEX 2    42\n",
      "1    37\n",
      "Name: SEX, dtype: int32\n",
      "AGE 32    4\n",
      "54    4\n",
      "14    3\n",
      "40    3\n",
      "36    3\n",
      "31    3\n",
      "15    3\n",
      "23    2\n",
      "64    2\n",
      "61    2\n",
      "25    2\n",
      "20    2\n",
      "77    2\n",
      "66    2\n",
      "62    2\n",
      "35    2\n",
      "47    2\n",
      "43    2\n",
      "41    2\n",
      "55    2\n",
      "16    2\n",
      "56    1\n",
      "38    1\n",
      "52    1\n",
      "63    1\n",
      "65    1\n",
      "44    1\n",
      "86    1\n",
      "30    1\n",
      "59    1\n",
      "21    1\n",
      "75    1\n",
      "49    1\n",
      "37    1\n",
      "19    1\n",
      "39    1\n",
      "98    1\n",
      "79    1\n",
      "70    1\n",
      "18    1\n",
      "22    1\n",
      "17    1\n",
      "51    1\n",
      "27    1\n",
      "57    1\n",
      "68    1\n",
      "74    1\n",
      "78    1\n",
      "82    1\n",
      "Name: AGE, dtype: int32\n",
      "INCTOT 0.0         14\n",
      "1135.0       4\n",
      "18387.0      3\n",
      "1589.0       3\n",
      "22927.0      3\n",
      "9307.0       3\n",
      "5675.0       2\n",
      "22019.0      2\n",
      "9761.0       2\n",
      "41087.0      2\n",
      "2951.0       2\n",
      "681.0        1\n",
      "12485.0      1\n",
      "19749.0      1\n",
      "227.0        1\n",
      "4313.0       1\n",
      "35185.0      1\n",
      "227000.0     1\n",
      "32461.0      1\n",
      "31553.0      1\n",
      "25651.0      1\n",
      "76499.0      1\n",
      "113727.0     1\n",
      "8399.0       1\n",
      "68327.0      1\n",
      "54707.0      1\n",
      "5221.0       1\n",
      "2497.0       1\n",
      "56523.0      1\n",
      "4767.0       1\n",
      "60609.0      1\n",
      "40179.0      1\n",
      "51075.0      1\n",
      "27921.0      1\n",
      "25197.0      1\n",
      "77861.0      1\n",
      "81039.0      1\n",
      "36547.0      1\n",
      "13393.0      1\n",
      "32007.0      1\n",
      "11123.0      1\n",
      "87849.0      1\n",
      "15663.0      1\n",
      "24289.0      1\n",
      "20657.0      1\n",
      "100561.0     1\n",
      "33823.0      1\n",
      "27467.0      1\n",
      "50621.0      1\n",
      "51983.0      1\n",
      "Name: INCTOT, dtype: int32\n",
      "EDUC 6     22\n",
      "2     15\n",
      "10     8\n",
      "3      7\n",
      "4      7\n",
      "11     6\n",
      "8      5\n",
      "7      4\n",
      "1      3\n",
      "5      1\n",
      "9      1\n",
      "Name: EDUC, dtype: int32\n",
      "EDUCD 60     20\n",
      "26      9\n",
      "100     8\n",
      "30      7\n",
      "40      7\n",
      "111     6\n",
      "80      5\n",
      "70      4\n",
      "25      3\n",
      "23      2\n",
      "14      2\n",
      "65      2\n",
      "90      1\n",
      "50      1\n",
      "22      1\n",
      "17      1\n",
      "Name: EDUCD, dtype: int32\n",
      "EDUC_HEAD  6.0     13\n",
      " 11.0    12\n",
      " 8.0     10\n",
      " 2.0     10\n",
      " 7.0      9\n",
      " 10.0     9\n",
      " 4.0      6\n",
      " 1.0      4\n",
      " 3.0      3\n",
      " 5.0      2\n",
      "-1.0      1\n",
      "Name: EDUC_HEAD, dtype: int32\n",
      "EDUC_POP -1.0     68\n",
      " 8.0      3\n",
      " 7.0      3\n",
      " 2.0      2\n",
      " 11.0     2\n",
      " 10.0     1\n",
      "Name: EDUC_POP, dtype: int32\n",
      "EDUC_MOM -1.0     64\n",
      " 6.0      8\n",
      " 10.0     3\n",
      " 3.0      2\n",
      " 7.0      1\n",
      " 2.0      1\n",
      "Name: EDUC_MOM, dtype: int32\n",
      "EDUCD_MOM2 -1.0    79\n",
      "Name: EDUCD_MOM2, dtype: int32\n",
      "EDUCD_POP2 -1.0    79\n",
      "Name: EDUCD_POP2, dtype: int32\n",
      "INCTOT_MOM -1.0       64\n",
      " 0.0        4\n",
      " 650.0      3\n",
      " 2050.0     2\n",
      " 4850.0     2\n",
      " 1150.0     2\n",
      " 7750.0     1\n",
      " 1250.0     1\n",
      "Name: INCTOT_MOM, dtype: int32\n",
      "INCTOT_POP -1.0        68\n",
      " 12050.0     3\n",
      " 50000.0     2\n",
      " 8850.0      2\n",
      " 7050.0      2\n",
      " 17850.0     1\n",
      " 13350.0     1\n",
      "Name: INCTOT_POP, dtype: int32\n",
      "INCTOT_MOM2 -1.0    79\n",
      "Name: INCTOT_MOM2, dtype: int32\n",
      "INCTOT_POP2 -1.0    79\n",
      "Name: INCTOT_POP2, dtype: int32\n",
      "INCTOT_HEAD  12050.0    5\n",
      " 50000.0    4\n",
      " 9050.0     4\n",
      " 8850.0     4\n",
      " 5050.0     4\n",
      " 7050.0     4\n",
      " 11250.0    3\n",
      " 17850.0    3\n",
      " 13350.0    3\n",
      " 8050.0     3\n",
      " 2150.0     3\n",
      " 25050.0    2\n",
      " 4850.0     2\n",
      " 250.0      2\n",
      " 4050.0     2\n",
      " 22150.0    2\n",
      " 6150.0     2\n",
      " 7450.0     2\n",
      " 2450.0     2\n",
      " 7750.0     2\n",
      " 11450.0    2\n",
      " 11150.0    2\n",
      " 6950.0     2\n",
      " 15050.0    2\n",
      " 19350.0    2\n",
      " 12450.0    2\n",
      " 16850.0    2\n",
      " 6050.0     2\n",
      " 2050.0     1\n",
      " 0.0        1\n",
      "-1.0        1\n",
      " 1250.0     1\n",
      " 17150.0    1\n",
      "Name: INCTOT_HEAD, dtype: int32\n",
      "SEX_HEAD  1.0    71\n",
      " 2.0     7\n",
      "-1.0     1\n",
      "Name: SEX_HEAD, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "\n",
    "keep_cols = ['YEAR', 'DATANUM', 'SERIAL', 'CBSERIAL', 'HHWT', 'GQ', 'PERNUM', 'SEX', 'AGE', 'INCTOT', 'EDUC', 'EDUCD', 'EDUC_HEAD', 'EDUC_POP', 'EDUC_MOM','EDUCD_MOM2','EDUCD_POP2', 'INCTOT_MOM','INCTOT_POP','INCTOT_MOM2','INCTOT_POP2', 'INCTOT_HEAD', 'SEX_HEAD']\n",
    "df = df.loc[:, keep_cols]\n",
    "#df = df.drop(col for col in df.columns if col not in keep_cols)\n",
    "for i in range(0, len(keep_cols)):\n",
    "    df[keep_cols[i]] = df[keep_cols[i]].fillna(-1)\n",
    "    print(keep_cols[i], df[keep_cols[i]].value_counts())\n",
    "    df[keep_cols[i]]= df[keep_cols[i]].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## I WANTED TO REDUCE THE 1980 SAMPLE HERE, BUT .SAMPLE() IS NEEDED AND NOT WORKING, UNLESS THERE IS A WORK AROUND..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the important data now clean and normalized, let's start doing the regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression\n",
    "We have 44 variables.  The other variables may provide important predictive information.  The Ridge Regression technique with cross validation to identify the best hyperparamters may be the best way to get the most accurate model.  We'll have to \n",
    "\n",
    "* define our performance metrics\n",
    "* split our data into train and test sets\n",
    "* train and test our model\n",
    "\n",
    "Let's begin and see what we get!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As our performance metrics we'll use a basic mean squared error and coefficient of determination implementation\n",
    "def mse(y_test, y_pred):\n",
    "    return ((y_test.reset_index(drop=True) - y_pred.reset_index(drop=True)) ** 2).mean()\n",
    "\n",
    "def cod(y_test, y_pred):\n",
    "    y_bar = y_test.mean()\n",
    "    total = ((y_test - y_bar) ** 2).sum()\n",
    "    residuals = ((y_test.reset_index(drop=True) - y_pred.reset_index(drop=True)) ** 2).sum()\n",
    "    return 1 - (residuals / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.preprocessing.model_selection import train_test_split\n",
    "trainsize = .9\n",
    "yCol = \"EDUC\"\n",
    "from cuml.preprocessing.model_selection import train_test_split\n",
    "from cuml.linear_model.ridge import Ridge\n",
    "\n",
    "def train_and_score(data, clf, train_frac=0.8, n_runs=20):\n",
    "    mse_scores, cod_scores = [], []\n",
    "    for _ in range(n_runs):\n",
    "        X_train, X_test, y_train, y_test = cuml.preprocessing.model_selection.train_test_split(df, yCol, train_size=.9)\n",
    "        y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "        mse_scores.append(mse(y_test, y_pred))\n",
    "        cod_scores.append(cod(y_test, y_pred))\n",
    "    return mse_scores, cod_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Results\n",
    " **Moment of truth!  Let's see how our regression training does!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median MSE (20 runs): 0.0373372816561586\n",
      "median COD (20 runs): 0.9951869736898369\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "n_runs = 20\n",
    "clf = Ridge()\n",
    "mse_scores, cod_scores = train_and_score(df, clf, n_runs=n_runs)\n",
    "print(f\"median MSE ({n_runs} runs): {np.median(mse_scores)}\")\n",
    "print(f\"median COD ({n_runs} runs): {np.median(cod_scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fun fact:** if you made INCTOT the y axis, your prediction results would not be so pretty!  It just shows that your education level can be an indicator for your income, but your income is NOT a great predictor for your education level.  You have better odds flipping a coin!\n",
    "\n",
    "* median MSE (50 runs): 518189521.07548225\n",
    "* median COD (50 runs): 0.425769113846303"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps/Self Study\n",
    "* You can pickle the model and use it in another workflow\n",
    "* You can redo the workflow with based on head of household using `EDUC`, `SEX`, and `INCTOT` for X in `X`_HEAD\n",
    "* You can see the growing role of education with women in their changing role in the workforce and income with \"EDUC_MOM\" and \"EDUC_POP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
