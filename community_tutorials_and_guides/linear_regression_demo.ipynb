{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2tZ3RLnlkrkg"
   },
   "source": [
    "# Intro to  Linear Regression with cuML\n",
    "Corresponding notebook to [*Beginner’s Guide to Linear Regression in Python with cuML*](http://bit.ly/cuml_lin_reg_friend) story on Medium\n",
    "\n",
    "Linear Regression is a simple machine learning model where the response `y` is modelled by a linear combination of the predictors in `X`. The `LinearRegression` function implemented in the `cuML` library allows users to change the `fit_intercept`, `normalize`, and `algorithm` parameters. \n",
    "\n",
    "Here is a brief on RAPIDS' Linear Regression parameters:\n",
    "\n",
    "- `algorithm`: 'eig' or 'svd' (default = 'eig')\n",
    "    - `Eig` uses a eigen decomposition of the covariance matrix, and is much faster\n",
    "    - `SVD` is slower, but guaranteed to be stable\n",
    "- `fit_intercept`: boolean (default = True)\n",
    "  - If `True`, `LinearRegresssion` tries to correct for the global mean of `y`\n",
    "  - If `False`, the model expects that you have centered the data.\n",
    "- `normalize`: boolean (default = False)\n",
    "  - If True, the predictors in X will be normalized by dividing by it’s L2 norm\n",
    "  - If False, no scaling will be done\n",
    "\n",
    "Methods that can be used with `LinearRegression` are:\n",
    "\n",
    "- `fit`: Fit the model with `X` and `y`\n",
    "- `get_params`: Sklearn style return parameter state\n",
    "- `predict`: Predicts the `y` for `X`\n",
    "- `set_params`: Sklearn style set parameter state to dictionary of params\n",
    "\n",
    "`cuML`'s `LinearRegression` expects expects either `cuDF` DataFrame or `cuPy`/`NumPy` matrix inputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N20le3_KlP3O"
   },
   "source": [
    "## Load data\n",
    "- for this demo, we will be utilizing the Boston housing dataset from `sklearn`\n",
    "  - start by loading in the set and printing a map of the contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RFE-nxxlTajg",
    "outputId": "04f89e88-61a3-4dd2-9088-123b410e508c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "# load Boston dataset\n",
    "boston = load_boston()\n",
    "\n",
    "# let's see what's inside\n",
    "print(boston.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wmcO8dxO0uOB"
   },
   "source": [
    "#### Boston house prices dataset\n",
    "- a description of the dataset is provided in `DESCR`\n",
    "  - let's explore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 923
    },
    "colab_type": "code",
    "id": "c3kLHAsP-Al2",
    "outputId": "02518c3c-7767-42a7-b6f4-6756ace741cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of black people by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# what do we know about this dataset?\n",
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wI_sB78vE297"
   },
   "source": [
    "### Build Dataframe\n",
    "- Import `cuDF` and input the data into a DataFrame \n",
    "  - Then add a `PRICE` column equal to the `target` key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "xiMmIZ8O5scJ",
    "outputId": "fd09db1f-fb41-4494-bb8b-eab6e18c258f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  PRICE  \n",
       "0     15.3  396.90   4.98   24.0  \n",
       "1     17.8  396.90   9.14   21.6  \n",
       "2     17.8  392.83   4.03   34.7  \n",
       "3     18.7  394.63   2.94   33.4  \n",
       "4     18.7  396.90   5.33   36.2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cudf\n",
    "\n",
    "# build dataframe from data key\n",
    "bos = cudf.DataFrame(list(boston.data))\n",
    "# set column names to feature_names\n",
    "bos.columns = boston.feature_names\n",
    "\n",
    "# add PRICE column from target\n",
    "bos['PRICE'] = boston.target\n",
    "\n",
    "# let's see what we're working with\n",
    "bos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r2qrTxo4ljZp"
   },
   "source": [
    "### Split Train from Test\n",
    "- For basic Linear Regression, we will predict `PRICE` (Median value of owner-occupied homes) based on `TAX` (full-value property-tax rate per $10,000)\n",
    "  - Go ahead and trim data to just these columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "spaDB10E3okF"
   },
   "outputs": [],
   "source": [
    "# simple linear regression X and Y\n",
    "X = bos['TAX']\n",
    "Y = bos['PRICE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4TKLv8FjIBuI"
   },
   "source": [
    "We can now set training and testing sets for our model\n",
    "- Use `cuML`'s `train_test_split` to do this\n",
    "  - Train on 70% of data\n",
    "  - Test on 30% of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "1DC6FHsNIKH_",
    "outputId": "4c932268-7a82-4ac3-c7b9-9966ffc2b12e"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cuml.preprocessing.model_selection'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9cbd856d6447>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcuml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# train/test split (70:30)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cuml.preprocessing.model_selection'"
     ]
    }
   ],
   "source": [
    "from cuml.preprocessing.model_selection import train_test_split\n",
    "\n",
    "# train/test split (70:30)\n",
    "sX_train, sX_test, sY_train, sY_test = train_test_split(X, Y, train_size = 0.7)\n",
    "\n",
    "# see what it looks like\n",
    "print(sX_train.shape)\n",
    "print(sX_test.shape)\n",
    "print(sY_train.shape)\n",
    "print(sY_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZLVg44gAmJG7"
   },
   "source": [
    "### Predict Values\n",
    "1. fit the model with `TAX` (*X_train*) and corresponding `PRICE` (*y_train*) values \n",
    "  - so it can build an understanding of their relationship \n",
    "2. predict `PRICE` (*y_test*) for a test set of `TAX` (*X_test*) values\n",
    "  - and compare `PRICE` predictions to actual median house (*y_test*) values\n",
    "    - use `sklearn`'s `mean_squared_error` to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZGMPloJxGtK3",
    "outputId": "664b54fe-16d5-4140-a657-3dc782574da9"
   },
   "outputs": [],
   "source": [
    "from cuml import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import cupy\n",
    "\n",
    "# call Linear Regression model\n",
    "slr = LinearRegression()\n",
    "\n",
    "# train the model\n",
    "slr.fit(sX_train, sY_train)\n",
    "\n",
    "# make predictions for test X values\n",
    "sY_pred = slr.predict(sX_test)\n",
    "\n",
    "# calculate error\n",
    "mse = mean_squared_error(cupy.asnumpy(sY_test), \n",
    "                         cupy.asnumpy(sY_pred))\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T7BXjkPSGwqd"
   },
   "source": [
    "3. visualize prediction accuracy with `matplotlib`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "colab_type": "code",
    "id": "pp9RNPt_Iemk",
    "outputId": "22a22472-50ad-4bb3-d104-35e9e100b8b6"
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# scatter actual and predicted results\n",
    "plt.scatter(cupy.asnumpy(sY_test), cupy.asnumpy(sY_pred))\n",
    "\n",
    "# label graph\n",
    "plt.xlabel(\"Actual Prices: $Y_i$\")\n",
    "plt.ylabel(\"Predicted prices: $\\hat{Y}_i$\")\n",
    "plt.title(\"Prices vs Predicted prices: $Y_i$ vs $\\hat{Y}_i$\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8MqX73B4s5tv"
   },
   "source": [
    "## Multiple Linear Regression \n",
    "- Our mean squared error for Simple Linear Regression looks kinda high.\n",
    "  - Let's try Multiple Linear Regression (predicting based on multiple variables rather than just `TAX`) and see if that produces more accurate predictions\n",
    "\n",
    "1. Set X to contain all values that are not `PRICE` from the unsplit data\n",
    "  - i.e. `CRIM`, `ZN`, `INDUS`, `CHAS`, `NOX`, `RM`, `AGE`, `DIS`, `RAD`, `TAX`, `PTRATIO`, `B`, `LSTAT`\n",
    "  - Y to still represent just 1 target value (`PRICE`)\n",
    "    - also from the unsplit data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZtQK5-f4M0Vg"
   },
   "outputs": [],
   "source": [
    "# set X to all variables except price\n",
    "mX = bos.drop('PRICE', axis=1)\n",
    "# and, like in the simple Linear Regression, set Y to price\n",
    "mY = bos['PRICE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RTYG4-UwNDsK"
   },
   "source": [
    "2. Split the data into `multi_X_train`, `multi_X_test`, `Y_train`, and `Y_test`\n",
    "  - Use `cuML`'s `train_test_split`\n",
    "    - And the same 70:30 train:test ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "EsKxK8u_F7t8",
    "outputId": "673a1a44-4d2f-4a45-8333-8f29782eaf65"
   },
   "outputs": [],
   "source": [
    "# train/test split (70:30)\n",
    "mX_train, mX_test, mY_train, mY_test = train_test_split(mX, mY, train_size = 0.7)\n",
    "\n",
    "# see what it looks like\n",
    "print(mX_train.shape)\n",
    "print(mX_test.shape)\n",
    "print(mY_train.shape)\n",
    "print(mY_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Y40R17LGHsI"
   },
   "source": [
    "3. fit the model with `multi_X_train` and corresponding `PRICE` (*y_train*) values \n",
    "  - so it can build an understanding of their relationships \n",
    "4. predict `PRICE` (*y_test*) for the test set of independent (*multi_X_test*) values\n",
    "  - and compare `PRICE` predictions to actual median house (*y_test*) values\n",
    "    - use `sklearn`'s `mean_squared_error` to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "N7qm1HuVO-1k",
    "outputId": "7e291cec-e602-4ad9-a5b3-b70d7261f63d"
   },
   "outputs": [],
   "source": [
    "# call Linear Regression model\n",
    "mlr = LinearRegression()\n",
    "\n",
    "# train the model for multiple regression\n",
    "mlr.fit(mX_train, mY_train)\n",
    "\n",
    "# make predictions for test X values\n",
    "mY_pred = mlr.predict(mX_test)\n",
    "\n",
    "# calculate error\n",
    "mmse = mean_squared_error(cupy.asnumpy(mY_test), \n",
    "                         cupy.asnumpy(mY_pred))\n",
    "print(mmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jTdmleXCM_Xb"
   },
   "source": [
    "5. visualize with `matplotlib`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "colab_type": "code",
    "id": "Q83NFMK1JKvL",
    "outputId": "569cfa77-a66e-4b1b-9d70-ae4ef8e7936e"
   },
   "outputs": [],
   "source": [
    "# scatter actual and predicted results\n",
    "plt.scatter(cupy.asnumpy(mY_test), cupy.asnumpy(mY_pred))\n",
    "\n",
    "# label graph\n",
    "plt.xlabel(\"Actual Prices: $Y_i$\")\n",
    "plt.ylabel(\"Predicted prices: $\\hat{Y}_i$\")\n",
    "plt.title(\"Prices vs Predicted prices: $Y_i$ vs $\\hat{Y}_i$\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2X1RA6sgtZQ6"
   },
   "source": [
    "## Conclusion\n",
    "- looks like the multiple regression we ran does provide more accurate predictions than the simple linear regression\n",
    "  - this will not always be the case, so always be sure to check and confirm if the extra computing is worth it\n",
    "\n",
    "Anyways, that's how you implement both Simple and Multiple Linear Regression with `cuML`. Go forth and do great things. Thanks for stopping by!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LOCAL_intro_lin_reg_cuml",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
