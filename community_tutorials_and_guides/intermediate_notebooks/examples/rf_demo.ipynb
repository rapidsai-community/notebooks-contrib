{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classification\n",
    "\n",
    "**Authorship**<br />\n",
    "Original Author: Saloni Jain<br />\n",
    "Last Edit: Taurean Dyer, 9/25/2019<br />\n",
    "\n",
    "**Test System Specs**<br />\n",
    "Test System Hardware: GV100<br />\n",
    "Test System Software: Ubuntu 18.04<br />\n",
    "RAPIDS Version: 0.10.0a - Docker Install<br />\n",
    "Driver: 410.79<br />\n",
    "CUDA: 10.0<br />\n",
    "\n",
    "\n",
    "**Known Working Systems**<br />\n",
    "RAPIDS Versions: 0.4, 0.5, 0.5.1, 0.6, 0.6.1, 0.7, 0.8, 0.9, 0.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro\n",
    "The Random Forest algorithm is a classification algorithm which builds several decision trees, and aggregates each of their outputs to make a prediction. This makes it more robust to overfitting.\n",
    "\n",
    "In order to convert your dataset to cudf format please read the cudf documentation on https://rapidsai.github.io/projects/cudf/en/latest/. For additional information on the RandomForest model please refer to the documentation on https://rapidsai.github.io/projects/cuml/en/latest/index.html\n",
    "\n",
    "This notebook demonstratrates fitting a RandomForestClassifier on the Higgs dataset. It is a binary classification problem to distinguish between a signal process which produces Higgs bosons and a background process which does not. The notebook also compares the performance (accuracy and speed) with sklearn's parallel RandomForestClassifier implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml import RandomForestClassifier as cuRF\n",
    "from sklearn.ensemble import RandomForestClassifier as sklRF\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cudf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function to download and extract the Higgs dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_higgs(compressed_filepath, decompressed_filepath):\n",
    "    higgs_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00280/HIGGS.csv.gz'\n",
    "    if not os.path.isfile(compressed_filepath):\n",
    "        urlretrieve(higgs_url, compressed_filepath)\n",
    "    if not os.path.isfile(decompressed_filepath):\n",
    "        cf = gzip.GzipFile(compressed_filepath)\n",
    "        with open(decompressed_filepath, 'wb') as df:\n",
    "            df.write(cf.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Higgs data and read using cudf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../data/rf/'\n",
    "if not os.path.exists(data_dir):\n",
    "    print('creating rf data directory')\n",
    "    os.system('mkdir ../../data/rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_filepath = data_dir+'HIGGS.csv.gz' # Set this as path for gzipped Higgs data file, if you already have\n",
    "decompressed_filepath = data_dir+'HIGGS.csv' # Set this as path for decompressed Higgs data file, if you already have\n",
    "download_higgs(compressed_filepath, decompressed_filepath)\n",
    "\n",
    "col_names = ['label'] + [\"col-{}\".format(i) for i in range(2, 30)] # Assign column names\n",
    "dtypes_ls = ['int32'] + ['float32' for _ in range(2, 30)] # Assign dtypes to each column\n",
    "data = cudf.read_csv(decompressed_filepath, names=col_names, dtype=dtypes_ls)\n",
    "data.head().to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make train test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data[data.columns.difference(['label'])].as_matrix(), data['label'].to_array() # Separate data into X and y\n",
    "del data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=500_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can consult RandomForestClassifier docstring to check all the parameters, but here are some of the more important ones: \n",
    "1. n_estimators: (default = 10) number of trees in the forest.\n",
    "2. max_depth: (default = -1) Maximum tree depth. Unlimited (i.e, until leaves are pure), if -1.\n",
    "3. n_bins: (default = 8) Number of bins used by the split algorithm.\n",
    "\n",
    "Note on `nbins`: Reducing `n_bins` shrinks the histograms used to compute which tree nodes to split. This reduction improves training time, but if you reduce it too low, you may harm model accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuml Random Forest params\n",
    "\n",
    "cu_rf_params = {\n",
    "    'n_estimators': 25,\n",
    "    'max_depth': 13,\n",
    "    'n_bins': 15,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The methods that can be used with the RandomForestClassifier are:\n",
    "1. fit: Fit the model with X and y.\n",
    "2. get_params: Sklearn style return parameter state\n",
    "3. predict: Predicts the y for X.\n",
    "4. set_params: Sklearn style set parameter state to dictionary of params.\n",
    "5. cross_validate: Predicts the accuracy of the model for X.\n",
    "\n",
    "###### Note on input to `fit` method: Since `fit` is processed on the GPU, it can accept `cudf` dataframes or `numpy` arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train cuml RF\n",
    "\n",
    "cu_rf = cuRF(**cu_rf_params)\n",
    "cu_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Sklearn params and fit RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn Random Forest params\n",
    "\n",
    "skl_rf_params = {\n",
    "    'n_estimators': 25,\n",
    "    'max_depth': 13,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train sklearn RF parallely\n",
    "\n",
    "skl_rf = sklRF(**skl_rf_params, n_jobs=20)\n",
    "skl_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict and compare cuml and sklearn RandomForestClassifier\n",
    "\n",
    "###### Note on input to cuml `predict` method: Since `predict` is processed on the CPU, it can only accept `numpy` arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "\n",
    "print(\"cuml RF Accuracy Score: \", accuracy_score(cu_rf.predict(X_test), y_test))\n",
    "print(\"sklearn RF Accuracy Score: \", accuracy_score(skl_rf.predict(X_test), y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
