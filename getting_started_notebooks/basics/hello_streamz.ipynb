{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hello World with cuDF and Streamz\n",
    "\n",
    "This notebook demonstrates use of cuDF to perform streaming word-count using a small portion of the [Streamz API](https://streamz.readthedocs.io/en/latest/).\n",
    "\n",
    "First, make sure you have installed the [Streamz](https://github.com/python-streamz/streamz) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /conda/envs/rapids\n",
      "\n",
      "  added / updated specs:\n",
      "    - streamz\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    streamz-0.5.1              |             py_0          44 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:          44 KB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  streamz            conda-forge/noarch::streamz-0.5.1-py_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "streamz-0.5.1        | 44 KB     | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge -y streamz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "First import the required packages. We'll be programmatically generating data and process in streaming batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from streamz import Stream\n",
    "import cudf, json\n",
    "\n",
    "# create a list of static messages\n",
    "messages = [\n",
    "    {'msg': 'Hello, World!'},\n",
    "    {'msg': 'hi, world!'},\n",
    "    {'msg': 'hey world'},\n",
    "    {'msg': 'Hi'}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define A Function to Run Per Batch\n",
    "\n",
    "While some streaming systems deal with single events at a time, using GPUs to run a per-event process is not ideal due to the high latency of PCI-E memory transfers and kernel call overhead.\n",
    "\n",
    "For our example, we'll focus on processing batches at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to run per batch\n",
    "def process_on_gpu(messages):\n",
    "    # read the batch of messages into a GPU DataFrame\n",
    "    df = cudf.read_json('\\n'.join(messages), lines=True)\n",
    "    \n",
    "    # split each line into columns, one per word\n",
    "    tmp = df['msg'].str.split()\n",
    "    \n",
    "    # combine all word columns into a single Series\n",
    "    words = tmp[tmp.columns[0]]\n",
    "    for word in tmp.columns[1:]:\n",
    "        words = words.append(tmp[word])\n",
    "    \n",
    "    # remove punctuation, lower-case\n",
    "    words = words.str.fillna('').replace(',', '').replace('!', '').str.lower()\n",
    "\n",
    "    # compute and return word counts for the batch\n",
    "    return str(words.groupby(words).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the Stream and Emit Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    2\n",
      "hello    3\n",
      "hey    2\n",
      "hi    5\n",
      "world    8\n",
      "dtype: int32\n",
      "    3\n",
      "hello    2\n",
      "hey    3\n",
      "hi    5\n",
      "world    7\n",
      "dtype: int32\n",
      "    2\n",
      "hello    3\n",
      "hey    2\n",
      "hi    5\n",
      "world    8\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "source = Stream()\n",
    "\n",
    "# GPUs like to process sizable chunks of data at once\n",
    "# source.partition(n) sends n events at a time to downstream functions\n",
    "source.partition(10).map(process_on_gpu).sink(print)\n",
    "\n",
    "# with 30 events partitioned by 10 events per group will give 3 \"batches\"\n",
    "n_messages = 30\n",
    "for idx in range(0, n_messages):\n",
    "    source.emit(json.dumps(messages[idx % len(messages)]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
