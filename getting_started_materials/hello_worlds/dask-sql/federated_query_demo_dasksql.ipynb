{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8AdUt3HiUrc3"
   },
   "source": [
    "# Querying Multiple Data Formats \n",
    "*By Winston Robson,\n",
    "Edited for Dask-SQL by Shondace Thomas*\n",
    "\n",
    "In this notebook, we will cover: \n",
    "- How to create DaskSQL tables from: \n",
    "    - Text file (CSV)\n",
    "    - Apache Parquet \n",
    "    - cuDF DataFrame (GDF)\n",
    "- How to `JOIN` multiple DaskSQL tables into one cuDF DataFrame with a single query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download Data\n",
    "This cell will check if you have the data for this demo, and, if you don't, will download it for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-12-10 08:33:53--  https://raw.githubusercontent.com/BlazingDB/bsql-demos/master/data/cancer_data_00.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1233 (1.2K) [text/plain]\n",
      "Saving to: ‘../../../data/dask-sql/cancer_data_00.csv’\n",
      "\n",
      "cancer_data_00.csv  100%[===================>]   1.20K  --.-KB/s    in 0s      \n",
      "\n",
      "2021-12-10 08:33:54 (35.2 MB/s) - ‘../../../data/dask-sql/cancer_data_00.csv’ saved [1233/1233]\n",
      "\n",
      "--2021-12-10 08:33:54--  https://blazingsql-colab.s3.amazonaws.com/cancer_data/cancer_data_01.parquet\n",
      "Resolving blazingsql-colab.s3.amazonaws.com (blazingsql-colab.s3.amazonaws.com)... 52.216.110.35\n",
      "Connecting to blazingsql-colab.s3.amazonaws.com (blazingsql-colab.s3.amazonaws.com)|52.216.110.35|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2364 (2.3K) [binary/octet-stream]\n",
      "Saving to: ‘../../../data/dask-sql/cancer_data_01.parquet’\n",
      "\n",
      "cancer_data_01.parq 100%[===================>]   2.31K  --.-KB/s    in 0s      \n",
      "\n",
      "2021-12-10 08:33:54 (72.7 MB/s) - ‘../../../data/dask-sql/cancer_data_01.parquet’ saved [2364/2364]\n",
      "\n",
      "--2021-12-10 08:33:55--  https://raw.githubusercontent.com/BlazingDB/bsql-demos/master/data/cancer_data_02.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1854 (1.8K) [text/plain]\n",
      "Saving to: ‘../../../data/dask-sql/cancer_data_02.csv’\n",
      "\n",
      "cancer_data_02.csv  100%[===================>]   1.81K  --.-KB/s    in 0s      \n",
      "\n",
      "2021-12-10 08:33:55 (22.6 MB/s) - ‘../../../data/dask-sql/cancer_data_02.csv’ saved [1854/1854]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# relative path to data folder\n",
    "data_dir = '../../../data/dask-sql/'\n",
    "\n",
    "# does folder exist?\n",
    "if not os.path.exists(data_dir):\n",
    "    print('creating dask-sql directory\\n')\n",
    "    # create folder\n",
    "    os.system('mkdir ../../data/dask-sql')\n",
    "\n",
    "# do we have file 0?\n",
    "if not os.path.isfile(data_dir + 'cancer_data_00.csv'):\n",
    "    !wget -P ../../../data/dask-sql https://raw.githubusercontent.com/BlazingDB/bsql-demos/master/data/cancer_data_00.csv\n",
    "\n",
    "# do we have file 1?\n",
    "if not os.path.isfile(data_dir + 'cancer_data_01.parquet'):\n",
    "    !wget -P ../../../data/dask-sql https://blazingsql-colab.s3.amazonaws.com/cancer_data/cancer_data_01.parquet\n",
    "\n",
    "# do we have file 2?\n",
    "if not os.path.isfile(data_dir + 'cancer_data_02.csv'):\n",
    "    !wget -P ../../../data/dask-sql https://raw.githubusercontent.com/BlazingDB/bsql-demos/master/data/cancer_data_02.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DaskContext\n",
    "You can think of the DaskContext much like a Spark Context (i.e. information such as FileSystems registered & Tables created will be stored)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "azZ7l2q7odYT",
    "outputId": "a5302d6e-307e-45c5-a682-c786cc999a40"
   },
   "outputs": [],
   "source": [
    "from dask_sql import Context\n",
    "# start up DaskSQL\n",
    "dc = Context()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Path\n",
    "Dask-SQL requires the full path to the data. This cell uses the `pwd` bash command to identify the path to this directory, then add it to the relative path to the notebooks-contrib `data` directory (i.e. what you'd type in Terminal to navigate to the data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/rapids/notebooks/extra/notebooks-contrib/data/dask-sql/'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bash command, returns SList w/ path (str) at 0th index\n",
    "path = !pwd\n",
    "\n",
    "# extract path to notebooks-contrib\n",
    "path = path[0].split('getting_started_materials')[0] \n",
    "\n",
    "# add path to Dask-SQL data\n",
    "path = path + 'data/dask-sql/'\n",
    "\n",
    "# what's it look like?\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N2bqpDEnZyQf"
   },
   "source": [
    "### Create Table from CSV\n",
    "Here we create a Dask-SQL table directly from a comma-separated values (CSV) file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HhRhj-ZvZygH"
   },
   "outputs": [],
   "source": [
    "# define column names and types\n",
    "col_names = ['diagnosis_result', 'radius', 'texture', 'perimeter']\n",
    "col_types = ['float32', 'float32', 'float32', 'float32'] \n",
    "\n",
    "# create table from CSV file\n",
    "dc.create_table('data_00', path +'cancer_data_00.csv', gpu=True, names=col_names, dtype=col_types)\n",
    "\n",
    "\n",
    "# df_result = dc.sql(\"SELECT * FROM data_00\")\n",
    "# df_result.head()\n",
    "# type(df_result)\n",
    "# df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HJFz-mqZTJ5Z"
   },
   "source": [
    "### Create Table from Parquet\n",
    "Here we create a Dask-SQL table directly from an Apache Parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HJuvtJDYTMyb"
   },
   "outputs": [],
   "source": [
    "# create table from Parquet file\n",
    "dc.create_table('data_01', path+'cancer_data_01.parquet', gpu= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "98HJFrt5TRa0"
   },
   "source": [
    "### Create Table from GPU DataFrame\n",
    "Here we use cuDF to create a GPU DataFrame (GDF), then use Dask-SQL to create a table from that GDF.\n",
    "\n",
    "The GDF is the standard memory representation for the RAPIDS AI ecosystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "14GwxmLsTV_p",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cudf\n",
    "\n",
    "# define column names & types\n",
    "col_names = ['compactness', 'symmetry', 'fractal_dimension']\n",
    "col_types = ['float32', 'float32', 'float32', 'float32']\n",
    "\n",
    "# make GPU DataFrame from CSV w/ cuDF\n",
    "gdf_02 = cudf.read_csv(path+'cancer_data_02.csv', names=col_names, dtype=col_types)\n",
    "\n",
    "# create BlazingSQL table from cuDF DataFrame\n",
    "dc.create_table('data_02', gdf_02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9DAZShZ2y-Nx"
   },
   "source": [
    "# Join Tables Together \n",
    "\n",
    "Now we can use Dask-SQL to join all three data formats in a single federated query. Dask-SQL queries return results as a cuDF DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "HOYSFebvzGcX",
    "outputId": "ad133dfd-540e-4142-8f12-a4a70d803bb6",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis_result</th>\n",
       "      <th>radius</th>\n",
       "      <th>texture</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>area</th>\n",
       "      <th>smoothness</th>\n",
       "      <th>compactness</th>\n",
       "      <th>symmetry</th>\n",
       "      <th>fractal_dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>668.0</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>451.0</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>451.0</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>954.0</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   diagnosis_result  radius  texture  perimeter   area  smoothness  \\\n",
       "0               0.0    16.0     14.0       86.0  520.0       0.108   \n",
       "1               1.0    10.0     24.0       97.0  668.0       0.117   \n",
       "2               1.0    23.0     26.0       78.0  451.0       0.105   \n",
       "3               1.0    23.0     26.0       78.0  451.0       0.105   \n",
       "4               1.0    23.0     12.0      151.0  954.0       0.143   \n",
       "\n",
       "   compactness  symmetry  fractal_dimension  \n",
       "0        0.154     0.194              0.069  \n",
       "1        0.148     0.195              0.067  \n",
       "2        0.071     0.190              0.066  \n",
       "3        0.071     0.162              0.057  \n",
       "4        0.278     0.242              0.079  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grab everything from data_00 & data_01 and area & smoothness from data_01\n",
    "query = '''\n",
    "        SELECT \n",
    "            a.*, \n",
    "            b.area, b.smoothness, \n",
    "            c.* \n",
    "        FROM \n",
    "            data_00 AS a\n",
    "        LEFT JOIN data_01 AS b\n",
    "            ON (a.perimeter = b.perimeter)\n",
    "        LEFT JOIN data_02 AS c\n",
    "            ON (b.compactness = c.compactness)\n",
    "            '''\n",
    "\n",
    "# join the tables together\n",
    "join = dc.sql(query)\n",
    "\n",
    "# display results (type(join)==cudf.core.dataframe.DataFrame)\n",
    "join.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_stuff took 1.8894765377044678s\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "print(f\"run_stuff took {t1-t0}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "316"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(join.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wygAeTIFTm2X"
   },
   "source": [
    "# You're Ready to Rock\n",
    "And... thats it! You are now live with Dask-SQL.\n",
    "\n",
    "Check out our [docs](https://dask-sql.readthedocs.io/) to get fancy or to learn more about how Dask-SQL works with the rest of [RAPIDS AI](https://rapids.ai/)."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "McVBO7GHRDzz"
   ],
   "name": "BlazingSQL_Federated_Query_Demo.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
