{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KDD 2020 \n",
    "# Where do I walk?\n",
    "Using RAPIDS to determine the shortest walking distance\n",
    "\n",
    "## Load the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autotime extension is already loaded. To reload it, use:\n",
      "  %reload_ext autotime\n",
      "time: 4.63 ms\n"
     ]
    }
   ],
   "source": [
    "import cudf\n",
    "from cuspatial import haversine_distance\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import cugraph\n",
    "\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.36 s\n"
     ]
    }
   ],
   "source": [
    "dtypes = OrderedDict([\n",
    "    ('OccupancyDateTime', 'date'),\n",
    "    ('PaidOccupancy', 'int64'),\n",
    "    ('BlockfaceName', 'str'),\n",
    "    ('SideOfStreet', 'str'),\n",
    "    ('SourceElementKey', 'int64'),\n",
    "    ('ParkingTimeLimitCategory', 'int64'),\n",
    "    ('ParkingSpaceCount', 'int64'),\n",
    "    ('PaidParkingArea', 'str'),\n",
    "    ('PaidParkingSubArea', 'str'),\n",
    "    ('PaidParkingRate', 'int8'),\n",
    "    ('ParkingCategory', 'str'),\n",
    "    ('Location', 'str'),\n",
    "    ('dow', 'int8')\n",
    "])\n",
    "\n",
    "df = cudf.read_csv(\n",
    "    '../data/parking_MayJun2019.csv'\n",
    "    , skiprows=1\n",
    "    , dtype=list(dtypes.values())\n",
    "    , names=list(dtypes.keys())\n",
    ")\n",
    "\n",
    "df = df[['SourceElementKey', 'Location']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 634 µs\n"
     ]
    }
   ],
   "source": [
    "def extractLon(location):\n",
    "    lon = location.str.extract('([0-9\\.\\-]+) ([0-9\\.]+)')[0]\n",
    "    return lon\n",
    "\n",
    "def extractLat(location):\n",
    "    lon = location.str.extract('([0-9\\.\\-]+) ([0-9\\.]+)')[1]\n",
    "    return lon\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.81 s\n"
     ]
    }
   ],
   "source": [
    "df['longitude'] = extractLon(df['Location']).astype('float')\n",
    "df['latitude'] = extractLat(df['Location']).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.12 s\n"
     ]
    }
   ],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"todrabas_test\")\n",
    "location = geolocator.geocode(\"400 Broad St, Seattle, WA 98109\") # SPACE NEEDLE\n",
    "\n",
    "df['LON_Ref'] = location.longitude\n",
    "df['LAT_Ref'] = location.latitude\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 29.6 ms\n"
     ]
    }
   ],
   "source": [
    "distances = haversine_distance(\n",
    "      df['longitude']\n",
    "    , df['latitude']\n",
    "    , df['LAT_Ref']\n",
    "    , df['LON_Ref']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As crow flies vs as people walk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the parking locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SourceElementKey</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4080</th>\n",
       "      <td>1001</td>\n",
       "      <td>-122.334694</td>\n",
       "      <td>47.602873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>1002</td>\n",
       "      <td>-122.334513</td>\n",
       "      <td>47.602949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4455</th>\n",
       "      <td>1006</td>\n",
       "      <td>-122.335143</td>\n",
       "      <td>47.603674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>1009</td>\n",
       "      <td>-122.336658</td>\n",
       "      <td>47.605018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3208</th>\n",
       "      <td>1010</td>\n",
       "      <td>-122.336447</td>\n",
       "      <td>47.605101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      SourceElementKey   longitude   latitude\n",
       "4080              1001 -122.334694  47.602873\n",
       "1336              1002 -122.334513  47.602949\n",
       "4455              1006 -122.335143  47.603674\n",
       "1026              1009 -122.336658  47.605018\n",
       "3208              1010 -122.336447  47.605101"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 506 ms\n"
     ]
    }
   ],
   "source": [
    "locations = df[['SourceElementKey', 'longitude', 'latitude']].drop_duplicates()\n",
    "locations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 18.2 ms\n"
     ]
    }
   ],
   "source": [
    "del df ## free up the GPU memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the graph data\n",
    "Thanks to John Murray for analyzing the map of King County roads and producing the data we will now use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download and unpack the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.4 ms\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "directory  = os.path.exists('../data')\n",
    "archive    = os.path.exists('../data/king_county_road_graph_20190909.tar.gz')\n",
    "file_graph = os.path.exists('../data/king_county_road_graph_20190909.csv')\n",
    "file_nodes = os.path.exists('../data/king_county_road_nodes_20190909.csv')\n",
    "\n",
    "if not directory:\n",
    "    os.mkdir('../data')\n",
    "\n",
    "if not archive:\n",
    "    import wget, shutil\n",
    "    \n",
    "    wget.download('http://tomdrabas.com/data/seattle_parking/king_county_road_graph_20190909.tar.gz')\n",
    "    shutil.move('king_county_road_graph_20190909.tar.gz', '../data/king_county_road_graph_20190909.tar.gz')\n",
    "    \n",
    "if not file_graph or not file_nodes:\n",
    "    import tarfile\n",
    "\n",
    "    tf = tarfile.open('../data/king_county_road_graph_20190909.tar.gz')\n",
    "    tf.extractall(path='../data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node1,node2,LENGTH\n",
      "89108,27652,5.02825\n",
      "27652,89108,5.02825\n",
      "27652,122930,112.417\n",
      "122930,27652,112.417\n",
      "36778,36779,48.2475\n",
      "36779,36778,48.2475\n",
      "26559,26559,48.3425\n",
      "26559,26559,48.3425\n",
      "2634,78382,372.325\n",
      "time: 583 ms\n"
     ]
    }
   ],
   "source": [
    "!head ../data/king_county_road_graph_20190909.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NodeID,Lon,Lat\n",
      "1,-121.431505,47.331052\n",
      "2,-121.430642,47.334726\n",
      "3,-121.404812,47.288757\n",
      "4,-121.408953,47.289157\n",
      "5,-121.432249,47.292963\n",
      "6,-121.432702,47.294297\n",
      "7,-121.432724,47.329542\n",
      "8,-121.367462,47.290593\n",
      "9,-121.360285,47.29045\n",
      "time: 577 ms\n"
     ]
    }
   ],
   "source": [
    "!head ../data/king_county_road_nodes_20190909.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's read the road data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 265 ms\n"
     ]
    }
   ],
   "source": [
    "road_graph_data = cudf.read_csv('../data/king_county_road_graph_20190909.csv')\n",
    "road_graph_data['node1'] = road_graph_data['node1'].astype('int32')\n",
    "road_graph_data['node2'] = road_graph_data['node2'].astype('int32')\n",
    "road_graph_data['LENGTH'] = road_graph_data['LENGTH'] * 3 # convert to feet as the LENGHT was given in yards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.73 ms\n"
     ]
    }
   ],
   "source": [
    "road_nodes = cudf.read_csv('../data/king_county_road_nodes_20190909.csv')\n",
    "road_nodes['NodeID'] = road_nodes['NodeID'].astype('int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the maximum of the `NodeID` so we can later append the parking nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127380"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.4 ms\n"
     ]
    }
   ],
   "source": [
    "nodeId = road_nodes['NodeID'].max()\n",
    "parking_nodes_idx = road_nodes['NodeID'].max() ## retain it so we can later filter the results to only parking locations\n",
    "nodeId"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move all the parking locations to host (via `.to_pandas()` method) so we can loop through all the ~1500 parking locations. Here, we also create an empty DataFrame that will hold the parking location nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 12.8 ms\n"
     ]
    }
   ],
   "source": [
    "parking_locations = locations.to_pandas().to_dict('records')\n",
    "parking_locations_nodes = cudf.DataFrame(columns=['NodeID', 'Lon', 'Lat', 'SourceElementKey'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's process the parking data. In this naive approach we simply search for 3 closest road intersections to the parking location. We will then add two edges to the overall graph that link the parking node to the nearest intersection. This approach currently is producing some artifacts but we will deal with this in the future; in this example we want to simply explore the efficacy of finding the shortest path between the nodes in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 30.3 s\n"
     ]
    }
   ],
   "source": [
    "for loc in parking_locations:\n",
    "    nodeId = nodeId + 1\n",
    "\n",
    "    ### calculate the distances to the road intersections\n",
    "    road_nodes['Lon_REF'] = loc['longitude']\n",
    "    road_nodes['Lat_REF'] = loc['latitude']\n",
    "    road_nodes['Distance'] = haversine_distance(\n",
    "          road_nodes['Lon']\n",
    "        , road_nodes['Lat']\n",
    "        , road_nodes['Lon_REF']\n",
    "        , road_nodes['Lat_REF'])\n",
    "    road_nodes['Distance'] = road_nodes['Distance']  * 0.621371 * 5280 # distance in feet as cuspatial returns kilometers\n",
    "\n",
    "    nearest = (\n",
    "        road_nodes\n",
    "        .nsmallest(3, 'Distance') # connect to the nearest 3 intersections\n",
    "    )\n",
    "    \n",
    "    nearest['node2'] = nodeId\n",
    "    nearest = (\n",
    "        nearest[['NodeID', 'node2', 'Distance']]\n",
    "        .rename(columns={'NodeID': 'node1', 'Distance': 'LENGTH'})\n",
    "    )\n",
    "    road_graph_data = cudf.concat([road_graph_data, nearest]) ## append to the road_graph_data DataFrame\n",
    "\n",
    "    ### add the parking node with its own unique NodeID\n",
    "    rec = {\n",
    "        'NodeID': nodeId\n",
    "        , 'Lon': loc['longitude']\n",
    "        , 'Lat': loc['latitude']\n",
    "        , 'SourceElementKey': loc['SourceElementKey']\n",
    "    }\n",
    "    parking_locations_tmp = cudf.DataFrame(rec)\n",
    "    parking_locations_nodes = cudf.concat([parking_locations_nodes, parking_locations_tmp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can find the nearest intersections from the Space Needle!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node1</th>\n",
       "      <th>node2</th>\n",
       "      <th>LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47756</th>\n",
       "      <td>128854</td>\n",
       "      <td>47757</td>\n",
       "      <td>175.906391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80448</th>\n",
       "      <td>128854</td>\n",
       "      <td>80449</td>\n",
       "      <td>200.062128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96739</th>\n",
       "      <td>128854</td>\n",
       "      <td>96740</td>\n",
       "      <td>261.056715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108797</th>\n",
       "      <td>128854</td>\n",
       "      <td>108798</td>\n",
       "      <td>277.221141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47827</th>\n",
       "      <td>128854</td>\n",
       "      <td>47828</td>\n",
       "      <td>301.715490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         node1   node2      LENGTH\n",
       "47756   128854   47757  175.906391\n",
       "80448   128854   80449  200.062128\n",
       "96739   128854   96740  261.056715\n",
       "108797  128854  108798  277.221141\n",
       "47827   128854   47828  301.715490"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 37.1 ms\n"
     ]
    }
   ],
   "source": [
    "road_nodes = (\n",
    "    cudf\n",
    "    .concat([road_nodes[['NodeID', 'Lon', 'Lat']], parking_locations_nodes])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "road_nodes['Lon_REF'] = location.longitude\n",
    "road_nodes['Lat_REF'] = location.latitude\n",
    "\n",
    "road_nodes['Distance'] = haversine_distance(\n",
    "          road_nodes['Lon']\n",
    "        , road_nodes['Lat']\n",
    "        , road_nodes['Lon_REF']\n",
    "        , road_nodes['Lat_REF'])\n",
    "\n",
    "road_nodes['Distance'] = road_nodes['Distance']  * 0.621371 * 5280\n",
    "\n",
    "space_needle_to_nearest_intersection = road_nodes.nsmallest(5, 'Distance') ### Space Needle is surrounded by around 5 road intersections hence we add 5\n",
    "space_needle_to_nearest_intersection_dist = space_needle_to_nearest_intersection['Distance'].to_array()[0]\n",
    "\n",
    "space_needle_to_nearest_intersection['node1'] = nodeId + 1\n",
    "space_needle_to_nearest_intersection = (\n",
    "    space_needle_to_nearest_intersection\n",
    "    .rename(columns={'NodeID': 'node2', 'Distance': 'LENGTH'})\n",
    "    [['node1', 'node2', 'LENGTH']]\n",
    ")\n",
    "road_graph_data = cudf.concat([space_needle_to_nearest_intersection, road_graph_data])\n",
    "space_needle_to_nearest_intersection ### SHOW THE EDGES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The road graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 60.3 ms\n"
     ]
    }
   ],
   "source": [
    "road_graph_data = road_graph_data.reset_index(drop=True)\n",
    "road_graph_data['node1'] = road_graph_data['node1'].astype('int32')\n",
    "road_graph_data['node2'] = road_graph_data['node2'].astype('int32')\n",
    "\n",
    "g = cugraph.Graph()\n",
    "g.from_cudf_edgelist(\n",
    "    road_graph_data\n",
    "    , source='node1'\n",
    "    , destination='node2'\n",
    "    , edge_attr='LENGTH'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the `.sssp(...)` method from `cugraph` to find the shortest distances to parking spots from the Space Needle!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>vertex</th>\n",
       "      <th>predecessor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77439</th>\n",
       "      <td>909.096479</td>\n",
       "      <td>128160</td>\n",
       "      <td>47830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81273</th>\n",
       "      <td>755.699182</td>\n",
       "      <td>128506</td>\n",
       "      <td>47756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86558</th>\n",
       "      <td>959.897433</td>\n",
       "      <td>128223</td>\n",
       "      <td>47830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86559</th>\n",
       "      <td>957.417489</td>\n",
       "      <td>128224</td>\n",
       "      <td>47830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98400</th>\n",
       "      <td>471.997029</td>\n",
       "      <td>127585</td>\n",
       "      <td>47828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98401</th>\n",
       "      <td>451.645186</td>\n",
       "      <td>127586</td>\n",
       "      <td>47828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101163</th>\n",
       "      <td>991.776494</td>\n",
       "      <td>127884</td>\n",
       "      <td>47831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102503</th>\n",
       "      <td>771.775981</td>\n",
       "      <td>127912</td>\n",
       "      <td>47829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102504</th>\n",
       "      <td>770.279039</td>\n",
       "      <td>127913</td>\n",
       "      <td>47829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107655</th>\n",
       "      <td>955.897882</td>\n",
       "      <td>127666</td>\n",
       "      <td>47799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107656</th>\n",
       "      <td>962.550373</td>\n",
       "      <td>127667</td>\n",
       "      <td>47799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117913</th>\n",
       "      <td>939.668006</td>\n",
       "      <td>127822</td>\n",
       "      <td>47831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117914</th>\n",
       "      <td>893.326728</td>\n",
       "      <td>127823</td>\n",
       "      <td>47831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124164</th>\n",
       "      <td>850.226265</td>\n",
       "      <td>128313</td>\n",
       "      <td>47797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126134</th>\n",
       "      <td>520.101226</td>\n",
       "      <td>128161</td>\n",
       "      <td>47828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          distance  vertex  predecessor\n",
       "77439   909.096479  128160        47830\n",
       "81273   755.699182  128506        47756\n",
       "86558   959.897433  128223        47830\n",
       "86559   957.417489  128224        47830\n",
       "98400   471.997029  127585        47828\n",
       "98401   451.645186  127586        47828\n",
       "101163  991.776494  127884        47831\n",
       "102503  771.775981  127912        47829\n",
       "102504  770.279039  127913        47829\n",
       "107655  955.897882  127666        47799\n",
       "107656  962.550373  127667        47799\n",
       "117913  939.668006  127822        47831\n",
       "117914  893.326728  127823        47831\n",
       "124164  850.226265  128313        47797\n",
       "126134  520.101226  128161        47828"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 329 ms\n"
     ]
    }
   ],
   "source": [
    "all_distances = cugraph.sssp(g, nodeId + 1)\n",
    "distances = all_distances.query('vertex > @parking_nodes_idx and vertex < @nodeId + 1 and distance < 1000')\n",
    "\n",
    "distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cugraph` returns a DataFrame with vertex, distance to that vertex, and the total distance traveled to that vertex from the `nodeId + 1` node -- the Space Needle. Here, we unfold the full path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing record: 0\n",
      "Processing record: 1\n",
      "Processing record: 2\n",
      "Processing record: 3\n",
      "Processing record: 4\n",
      "Processing record: 5\n",
      "Processing record: 6\n",
      "Processing record: 7\n",
      "Processing record: 8\n",
      "Processing record: 9\n",
      "Processing record: 10\n",
      "Processing record: 11\n",
      "Processing record: 12\n",
      "Processing record: 13\n",
      "Processing record: 14\n",
      "time: 632 ms\n"
     ]
    }
   ],
   "source": [
    "# unfold -- create the whole path\n",
    "closest_node = nodeId + 1\n",
    "parking_cnt = distances['vertex'].count()\n",
    "\n",
    "for i in range(parking_cnt):\n",
    "    print('Processing record: {0}'.format(i))\n",
    "    parking_node = distances.iloc[i].to_pandas()\n",
    "    vertex = int(parking_node[1])\n",
    "    predecessor = int(parking_node[2])\n",
    "    \n",
    "    if i == 0:\n",
    "        paths = all_distances.query('vertex == @vertex')\n",
    "    else:\n",
    "        paths = cudf.concat([all_distances.query('vertex == @vertex'), paths])\n",
    "\n",
    "    while vertex != closest_node:\n",
    "        temp = all_distances.query('vertex == @predecessor')\n",
    "        paths = cudf.concat([temp, paths])\n",
    "        predecessor = temp['predecessor'].to_array()[0]\n",
    "        vertex = temp['vertex'].to_array()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Charting the paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 127 ms\n"
     ]
    }
   ],
   "source": [
    "paths['vertex'] = paths['vertex'].astype('int64')\n",
    "paths['predecessor'] = paths['predecessor'].astype('int64')\n",
    "paths = paths.drop_duplicates()\n",
    "\n",
    "### process the data so we get the Lat/Lon back for both src and dest\n",
    "### then move to host\n",
    "paths_host = (\n",
    "    paths\n",
    "    .rename(columns={'vertex': 'NodeID'})\n",
    "    .merge(road_nodes[['NodeID', 'Lat', 'Lon']], on='NodeID', how='left')\n",
    "    .rename(columns={'NodeID': 'vertex', 'predecessor': 'NodeID'})\n",
    "    .merge(road_nodes[['NodeID', 'Lat', 'Lon']], on='NodeID', how='left')\n",
    "    .fillna({'Lat_y': location.latitude, 'Lon_y': location.longitude})\n",
    "    [['vertex', 'Lat_x', 'Lon_x', 'Lat_y', 'Lon_y']]\n",
    "    .query('vertex < @nodeId + 1')\n",
    "    .to_pandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the information about the parking spots so we can create info boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.49 ms\n"
     ]
    }
   ],
   "source": [
    "distances['vertex'] = distances['vertex'].astype('int64')\n",
    "distances_host = (\n",
    "    distances\n",
    "    .rename(columns={'vertex': 'NodeID'})\n",
    "    .merge(road_nodes[['NodeID', 'Lat', 'Lon', 'SourceElementKey']], on='NodeID')\n",
    "    [['SourceElementKey', 'Lat', 'Lon', 'distance']]\n",
    "    .to_pandas()\n",
    "#     .to_dict('records')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 893 µs\n"
     ]
    }
   ],
   "source": [
    "info_box_template = \"\"\"\n",
    "<dl>\n",
    "<dt>SourceElementKey</dt><dd>{SourceElementKey}</dd>\n",
    "<dt>Distance</dt><dd>{distance:.0f} ft.</dd>\n",
    "</dl>\n",
    "\"\"\"\n",
    "\n",
    "parking_info = [info_box_template.format(**parking) for parking in distances_host.to_dict('records')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And... plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 108 ms\n"
     ]
    }
   ],
   "source": [
    "import gmaps\n",
    "from ipywidgets.embed import embed_minimal_html\n",
    "\n",
    "####################################################\n",
    "##                                                ##\n",
    "## CHANGE THE API CREDS IN THE GoogleMapsAPI.cred ##\n",
    "##                                                ##\n",
    "####################################################\n",
    "with open('config/GoogleMapsAPI.cred', 'r') as f:\n",
    "    gmaps_creds = f.read()\n",
    "\n",
    "gmaps.configure(api_key=gmaps_creds) # Your Google API key, go to https://console.developers.google.com\n",
    "parking_layer = gmaps.symbol_layer(\n",
    "    distances_host[['Lat', 'Lon']], fill_color=\"green\", stroke_color=\"green\", scale=3, info_box_content=parking_info\n",
    ")\n",
    "\n",
    "destinations_layer = gmaps.symbol_layer(\n",
    "    [[location.latitude, location.longitude]]\n",
    "    , info_box_content=['DESTINATION']\n",
    "    , scale=5\n",
    "    , fill_color=\"red\"\n",
    "    , stroke_color=\"red\"\n",
    ")\n",
    "\n",
    "lines_layer = gmaps.drawing_layer(features=[\n",
    "    gmaps.Line(\n",
    "          start = (path['Lat_x'], path['Lon_x'])\n",
    "        , end   = (path['Lat_y'], path['Lon_y'])\n",
    "        , stroke_weight=2\n",
    "        , stroke_color=\"red\"\n",
    "    )\n",
    "    for path in paths_host.to_dict('records')]\n",
    ")\n",
    "\n",
    "fig = gmaps.figure(layout={'height': '500px'})\n",
    "fig.add_layer(parking_layer)\n",
    "fig.add_layer(destinations_layer)\n",
    "fig.add_layer(lines_layer)\n",
    "embed_minimal_html('maps_rendered/map_walk_interim.html', views=[fig])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
