{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark and Bounds Tests\n",
    "\n",
    "The purpose of this notebook is to benchmark all of the single GPU cuML algorithms against their skLearn counterparts, while also providing the ability to find and verify upper bounds. This version of the `cuml_benchmarks` is meant to complete faster than the full version and on GPUs will smaller memory capacities.  If you need an exhaustive benchmark, please use the `cuml_benchmarks` notebook.\n",
    "\n",
    "This benchmark will persist results into a file so that benchmarking may be continued, in the case of failure. \n",
    "\n",
    "Also supported is the ability to draw charts with the results, which should aid in presentations and transparency to end-users. \n",
    "\n",
    "**Note: if you get a Memory Error, please reduce your upper bound bench_rows to something that will fit in your GPU's memory.  This benchmark is Single GPU only, and you will have the opportunity to choose which GPU you want to benchmark**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Credits\n",
    "**Authorship**<br />\n",
    "Original Author: Taurean Dyer, based on the work of Corey Nolet's original [cuML Benchmarks](intermediate_notebooks/benchmarks/cuml_benchmarks.ipynb)<br />\n",
    "Last Edit: Taurean Dyer, 9/25/2019<br />\n",
    "\n",
    "**Test System Specs**<br />\n",
    "Test System Hardware: GV100<br />\n",
    "Test System Software: Ubuntu 18.04<br />\n",
    "RAPIDS Version: 0.10.0a - Docker Install<br />\n",
    "Driver: 410.79<br />\n",
    "CUDA: 10.0<br />\n",
    "\n",
    "\n",
    "**Known Working Systems**<br />\n",
    "RAPIDS Versions: 0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cudf\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import cuml\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 40, 20\n",
    "rcParams['figure.dpi'] = 100\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "\n",
    "print(cuml.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Please choose the GPU you'll be benchmarking and set its ID in the OS environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" # Choose GPU here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default parameters\n",
    "\n",
    "N_JOBS_SKLEARN = -1            # Passed to the n_jobs parameter, indicates number of cpu jobs to run\n",
    "                               # Note that some sklearn algorithms do not support n_jobs (e.g. PCA), so they run a single job\n",
    "RERUN_BENCH = True             # Set to true to force re-running even if a result is cached\n",
    "MAX_BENCH_ROW_COUNTS = -1      # When iterating over many row sizes, only consider first N options (for faster testing, set to -1 for all options)\n",
    "MAX_BENCH_FEATURE_COUNTS = -1  # When iterating over many feature counts, only consider first N options (for faster testing, set to -1 for all options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark function definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "\n",
    "def load_data_mortgage_X(nrows, ncols, cached = '../../data/mortgage/mortgage.npy.gz',source='mortgage', dtype = np.float32):\n",
    "    print(\"Loading \" + str(cached))\n",
    "    if os.path.exists(cached) and source=='mortgage':\n",
    "        print('use mortgage data')\n",
    "        with gzip.open(cached) as f:\n",
    "            X = np.load(f)\n",
    "        X = X[np.random.randint(0,X.shape[0]-1,nrows),:ncols]\n",
    "    else:\n",
    "        print('use random data')\n",
    "        X = np.random.random((nrows,ncols)).astype(dtype)\n",
    "    df = pd.DataFrame({'fea%d'%i:X[:,i] for i in range(X.shape[1])}).fillna(0)\n",
    "    return df\n",
    "\n",
    "def load_data_mortgage_Xy(nrows, ncols, dtype = np.float32):\n",
    "    \"\"\"\n",
    "    Generate a dataframe and series based on rows and cols\n",
    "    \"\"\"\n",
    "    X = load_data_mortgage_X(nrows, ncols, dtype = dtype)\n",
    "    y = load_data_mortgage_X(nrows, 1, dtype = dtype)[\"fea0\"]\n",
    "    return (X, y)\n",
    "\n",
    "\n",
    "def load_data_X(nrows, ncols, dtype = np.float32):\n",
    "    \"\"\"\n",
    "    Generate a single dataframe with specified rows and cols\n",
    "    \"\"\"\n",
    "    X = np.random.uniform(-1, 1, (nrows,ncols))\n",
    "    df = pd.DataFrame({'fea%d'%i:X[:,i].astype(dtype) for i in range(X.shape[1])})\n",
    "    return df\n",
    "\n",
    "def load_data_Xy(nrows, ncols, dtype = np.float32):\n",
    "    \"\"\"\n",
    "    Generate a dataframe and series based on rows and cols\n",
    "    \"\"\"\n",
    "    X = load_data_X(nrows, ncols, dtype)\n",
    "    y = load_data_X(nrows, 1, dtype)[\"fea0\"]\n",
    "    return (X, y)\n",
    "\n",
    "def load_data_X_npy(nrows, ncols, dtype=np.float32):\n",
    "    return np.random.uniform(-1, 1,(nrows, ncols))\n",
    "\n",
    "def load_data_Xy_npy(nrows, ncols, dtype = np.float32):\n",
    "    X = load_data_X_npy(nrows, ncols, dtype)\n",
    "    y = load_data_X_npy(nrows, 1, dtype)\n",
    "    return (X, y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_convert(data):\n",
    "    if isinstance(data, tuple):\n",
    "        return tuple([pandas_convert(d) for d in data])\n",
    "    elif isinstance(data, pd.DataFrame):\n",
    "        return cudf.DataFrame.from_pandas(data)\n",
    "    elif isinstance(data, pd.Series):\n",
    "        return cudf.Series.from_pandas(data)\n",
    "    else:\n",
    "        raise Exception(\"Unsupported type %s\" % str(type(data)))\n",
    "        \n",
    "def no_convert(data):\n",
    "    if isinstance(data, tuple):\n",
    "        return tuple([d for d in data])\n",
    "    elif isinstance(data, np.ndarray):\n",
    "        return data\n",
    "    else:\n",
    "        raise Exception(\"Unsupported type %s\" % str(type(data)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pluggable benchmark function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeedupBenchmark(object):\n",
    "    \n",
    "    def __init__(self, converter = pandas_convert):\n",
    "        self.name = \"speedup\"\n",
    "        self.converter = converter\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"Speedup\"\n",
    "    \n",
    "    def run(self, algo, rows, dims, data):\n",
    "\n",
    "        data2 = self.converter(data)\n",
    "        cu_start = time.time()\n",
    "        algo.cuml(data2)\n",
    "        cu_elapsed = time.time() - cu_start\n",
    "        \n",
    "        sk_start = time.time()\n",
    "        algo.sk(data)\n",
    "        sk_elapsed = time.time() - float(sk_start)\n",
    "\n",
    "        # Needs to return the calculation and the name given to it.\n",
    "        return sk_elapsed / float(cu_elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BenchmarkRunner(object):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 benchmarks = [SpeedupBenchmark()],\n",
    "                 out_filename = \"benchmark.pickle\",\n",
    "                 rerun = RERUN_BENCH,\n",
    "                 n_runs = 3,\n",
    "                 bench_rows = [2**x for x in range(13, 20)],\n",
    "                 bench_dims = [64, 128, 256, 512]):\n",
    "\n",
    "        self.benchmarks = benchmarks\n",
    "        self.rerun = rerun\n",
    "        self.n_runs = n_runs\n",
    "        self.bench_rows = bench_rows[:MAX_BENCH_ROW_COUNTS]\n",
    "        self.bench_dims = bench_dims[:MAX_BENCH_FEATURE_COUNTS]\n",
    "        self.out_filename = out_filename        \n",
    "        \n",
    "    def load_results(self):\n",
    "        \n",
    "        if os.path.exists(self.out_filename):\n",
    "            print(\"Loaded previous benchmark results from %s\" % (self.out_filename))\n",
    "            with open(self.out_filename, 'rb') as f:\n",
    "                return pickle.load(f)\n",
    "                \n",
    "        else:\n",
    "            return {}\n",
    "        \n",
    "    def store_results(self, final_results):\n",
    "        with open(self.out_filename, 'wb') as f:\n",
    "            pickle.dump(final_results, f)\n",
    "        \n",
    "            \n",
    "    def run(self, algo):\n",
    "        \n",
    "        final_results = self.load_results()\n",
    "        \n",
    "        for benchmark in self.benchmarks:\n",
    "            if algo.name in final_results:\n",
    "                results = final_results[algo.name]\n",
    "            else:\n",
    "                results = {}\n",
    "                final_results[algo.name] = results\n",
    "\n",
    "            for n_rows in self.bench_rows:\n",
    "                for n_dims in self.bench_dims:     \n",
    "                    if (n_rows, n_dims, benchmark.name) not in results or self.rerun:\n",
    "\n",
    "                        print(\"Running %s. (nrows=%d, n_dims=%d)\" % (str(algo), n_rows, n_dims))\n",
    "\n",
    "                        data = algo.load_data(n_rows, n_dims)\n",
    "                        runs = [benchmark.run(algo, n_rows, n_dims, data) for i in range(self.n_runs)]\n",
    "                        results[(n_rows, n_dims, benchmark.name)] = np.mean(runs)\n",
    "\n",
    "                        print(\"Benchmark for %s = %f\" % (str((n_rows, n_dims, benchmark.name)), \n",
    "                                                         results[(n_rows, n_dims, benchmark.name)]))\n",
    "                        \n",
    "                        self.store_results(final_results)\n",
    "\n",
    "                            \n",
    "    def chart(self, algo, title = \"cuML vs SKLearn\"):\n",
    "        \n",
    "        for benchmark in self.benchmarks:\n",
    "        \n",
    "            results = self.load_results()[algo.name]\n",
    "\n",
    "            final = {}\n",
    "\n",
    "            plts = []\n",
    "            for dim in self.bench_dims:\n",
    "                data = {k: v for (k, v) in results.items() if dim == k[1]}\n",
    "\n",
    "                if len(data) > 0:\n",
    "                    data = [(k[0], v) for k, v in data.items()]\n",
    "                    data.sort(key = lambda x: x[0])\n",
    "\n",
    "                    final[dim] = list(map(lambda x: x[1], data))\n",
    "\n",
    "                    keys = list(map(lambda x: np.log2(x[0]), data))\n",
    "                line = plt.plot(keys, final[dim], label = str(dim), linewidth = 3,  marker = 'o', markersize = 7)\n",
    "\n",
    "                plts.append(line[0])\n",
    "            leg = plt.legend(handles = plts, fontsize = 30)\n",
    "            leg.set_title(\"Dimensions\", prop = {'size':'x-large'})    \n",
    "            plt.title(\"%s %s: %s\" % (algo, benchmark, title), fontsize = 30)\n",
    "\n",
    "            plt.ylabel(str(benchmark), fontsize = 20)\n",
    "            plt.xlabel(\"Training Examples (2^x)\", fontsize = 40)\n",
    "\n",
    "            plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "            plt.tick_params(axis='both', which='minor', labelsize=15)\n",
    "\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseAlgorithm(object):\n",
    "    def __init__(self, load_data = load_data_X):\n",
    "        self.load_data = load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarks and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from cuml.neighbors import NearestNeighbors as cumlNN\n",
    "\n",
    "class NearestNeighborsAlgo(BaseAlgorithm):\n",
    "    \n",
    "    def __init__(self, n_neighbors = 1024, load_data = load_data_X):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.name = \"nearest_neighbors\"\n",
    "\n",
    "        BaseAlgorithm.__init__(self, load_data)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"NearestNeighbors\"\n",
    "        \n",
    "    def sk(self, X):\n",
    "        knn_sk = NearestNeighbors(n_neighbors = self.n_neighbors, algorithm = 'brute', n_jobs=N_JOBS_SKLEARN)\n",
    "        knn_sk.fit(X)\n",
    "        D_sk,I_sk = knn_sk.kneighbors(X[0:100])\n",
    "\n",
    "    def cuml(self, X):\n",
    "        knn_cuml = cumlNN(n_neighbors = self.n_neighbors)\n",
    "        knn_cuml.fit(X)\n",
    "        D_cuml,I_cuml = knn_cuml.kneighbors(X[0:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = BenchmarkRunner(benchmarks = [SpeedupBenchmark(no_convert)], bench_rows = [2**x for x in range(11, 17)])\n",
    "runner.run(NearestNeighborsAlgo(load_data = load_data_X_npy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = BenchmarkRunner()\n",
    "runner.chart(NearestNeighborsAlgo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN as skDBSCAN\n",
    "from cuml import DBSCAN as cumlDBSCAN\n",
    "\n",
    "class DBSCANAlgo(BaseAlgorithm):\n",
    "    \n",
    "    def __init__(self, eps = 3, min_samples = 2):\n",
    "        self.name = \"dbscan\"\n",
    "        self.eps = 3\n",
    "        self.min_samples = 2\n",
    "        BaseAlgorithm.__init__(self)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"DBSCAN\"\n",
    "\n",
    "    def sk(self, X):\n",
    "        clustering_sk = skDBSCAN(eps = self.eps, min_samples = self.min_samples, algorithm = \"brute\", n_jobs=N_JOBS_SKLEARN)\n",
    "        clustering_sk.fit(X)\n",
    "\n",
    "    def cuml(self, X):\n",
    "        clustering_cuml = cumlDBSCAN(eps = self.eps, min_samples = self.min_samples)\n",
    "        clustering_cuml.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = BenchmarkRunner(bench_rows = [2**x for x in range(10, 17)])\n",
    "runner.run(DBSCANAlgo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = BenchmarkRunner(bench_rows = [2**x for x in range(10, 17)])\n",
    "runner.chart(DBSCANAlgo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP as skUMAP\n",
    "from cuml.manifold.umap import UMAP as cumlUMAP\n",
    "\n",
    "class UMAPAlgo(BaseAlgorithm):\n",
    "    \n",
    "    def __init__(self, n_neighbors = 5, n_epochs = 500):\n",
    "        self.name = \"umap\"\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.n_epochs = n_epochs\n",
    "        BaseAlgorithm.__init__(self)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"UMAP\"\n",
    "\n",
    "    def sk(self, X):\n",
    "        clustering_sk = skUMAP(n_neighbors = self.n_neighbors, n_epochs = self.n_epochs)\n",
    "        clustering_sk.fit(X)\n",
    "\n",
    "    def cuml(self, X):\n",
    "        clustering_cuml = cumlUMAP(n_neighbors = self.n_neighbors, n_epochs = self.n_epochs)\n",
    "        clustering_cuml.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "runner = BenchmarkRunner(bench_rows = [2**x for x in range(12, 16)])\n",
    "runner.run(UMAPAlgo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = BenchmarkRunner(bench_rows = [2**x for x in range(12, 16)])\n",
    "runner.chart(UMAPAlgo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans as skKmeans\n",
    "from cuml.cluster import KMeans as cumlKmeans\n",
    "\n",
    "class KMeansAlgo(BaseAlgorithm):\n",
    "    \n",
    "    def __init__(self, n_clusters=5):\n",
    "        self.name = \"kmeans\"\n",
    "        self.n_clusters = n_clusters\n",
    "        BaseAlgorithm.__init__(self, load_data_X_npy)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"KMeans\"\n",
    "\n",
    "    def sk(self, X):\n",
    "        clustering_sk = skKmeans(n_clusters=self.n_clusters, n_jobs=N_JOBS_SKLEARN)\n",
    "        clustering_sk.fit(X)\n",
    "\n",
    "    def cuml(self, X):\n",
    "        clustering_cuml = cumlKmeans(n_clusters=self.n_clusters)\n",
    "        clustering_cuml.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = BenchmarkRunner(benchmarks = [SpeedupBenchmark(no_convert)], bench_rows = [2**x for x in range(12, 18, 2)])\n",
    "runner.run(KMeansAlgo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = BenchmarkRunner(bench_rows = [2**x for x in range(12, 18, 2)])\n",
    "runner.chart(KMeansAlgo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression as skLR\n",
    "from cuml.linear_model import LinearRegression as cumlLR\n",
    "\n",
    "class LinearRegressionAlgo(BaseAlgorithm):\n",
    "    def __init__(self):\n",
    "        BaseAlgorithm.__init__(self, load_data_Xy)\n",
    "        self.name = \"linear_regression\"\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"Linear Regression\"\n",
    "\n",
    "    def sk(self, data):\n",
    "        X, y = data\n",
    "        clustering_sk = skLR(n_jobs=N_JOBS_SKLEARN)\n",
    "        clustering_sk.fit(X, y)\n",
    "\n",
    "    def cuml(self, data):\n",
    "        X, y = data\n",
    "        cuml_lr = cumlLR()\n",
    "        cuml_lr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = BenchmarkRunner(bench_rows = [2**x for x in range(15, 18)])\n",
    "runner.run(LinearRegressionAlgo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = BenchmarkRunner(bench_rows = [2**x for x in range(15, 18)])\n",
    "runner.chart(LinearRegressionAlgo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA / SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA as skPCA\n",
    "from cuml import PCA as cumlPCA\n",
    "\n",
    "class PCAAlgo(BaseAlgorithm):\n",
    "    \n",
    "    def __init__(self, n_components = 10, load_data = load_data_mortgage_X):\n",
    "        self.n_components = 10\n",
    "        self.name = \"pca\"\n",
    "        BaseAlgorithm.__init__(self, load_data = load_data)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"PCA\"\n",
    "\n",
    "    def sk(self, X):\n",
    "        skpca = skPCA(n_components = 10)\n",
    "        skpca.fit(X)\n",
    "\n",
    "    def cuml(self, X):\n",
    "        cumlpca = cumlPCA(n_components = 10)\n",
    "        cumlpca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = BenchmarkRunner(bench_rows = [2**x for x in range(18, 20)])\n",
    "runner.run(PCAAlgo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = BenchmarkRunner(bench_rows = [2**x for x in range(18, 20)])\n",
    "runner.chart(PCAAlgo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as skRFC\n",
    "from cuml.ensemble import RandomForestClassifier as cumlRFC\n",
    "\n",
    "class RandomForestClassifierAlgo(BaseAlgorithm):\n",
    "    \n",
    "    def __init__(self, n_estimators = 1000, max_depth = 8, load_data = load_data_mortgage_Xy):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.name = \"random_forest_classifier\"\n",
    "        BaseAlgorithm.__init__(self, load_data = load_data)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"Random Forest Classifier\"\n",
    "\n",
    "    def sk(self, data):\n",
    "        X, y = data\n",
    "        skrfc = skRFC(n_jobs = -1, n_estimators = self.n_estimators, max_depth = self.max_depth)\n",
    "        skrfc.fit(X, y.astype(np.int32))\n",
    "        \n",
    "    def cuml(self, data):\n",
    "        X, y = data\n",
    "        cumlrfc = cumlRFC(n_estimators = self.n_estimators, max_depth = self.max_depth)\n",
    "        cumlrfc.fit(X, y.astype(np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = BenchmarkRunner(bench_rows = [2**x for x in range(18, 20)])\n",
    "runner.run(RandomForestClassifierAlgo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = BenchmarkRunner(bench_rows = [2**x for x in range(18, 20)])\n",
    "runner.chart(RandomForestClassifierAlgo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.random_projection import GaussianRandomProjection as skGRP\n",
    "from cuml.random_projection import GaussianRandomProjection as cumlGRP\n",
    "\n",
    "class GaussianRandomProjectionAlgo(BaseAlgorithm):\n",
    "    \n",
    "    def __init__(self, load_data = load_data_mortgage_X):\n",
    "        self.name = \"gaussian_random_projection\"\n",
    "        BaseAlgorithm.__init__(self, load_data = load_data)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"Gaussian Random Projection\"\n",
    "\n",
    "    def sk(self, data):\n",
    "        X = data\n",
    "        skrfc = skGRP(n_components = 2)\n",
    "        skrfc.fit(X)\n",
    "        skrfc.transform(X)\n",
    "\n",
    "    def cuml(self, data):\n",
    "        X = data\n",
    "        cumlrfc = cumlGRP(n_components = 2)\n",
    "        cumlrfc.fit(X)\n",
    "        cumlrfc.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = BenchmarkRunner(bench_rows = [2**x for x in range(11, 20)])\n",
    "runner.run(GaussianRandomProjectionAlgo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.random_projection import SparseRandomProjection as skSRP\n",
    "from cuml.random_projection import SparseRandomProjection as cumlSRP\n",
    "\n",
    "class SparseRandomProjection(BaseAlgorithm):\n",
    "    \n",
    "    def __init__(self, load_data = load_data_mortgage_X):\n",
    "        self.name = \"gaussian_random_projection\"\n",
    "        BaseAlgorithm.__init__(self, load_data = load_data)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"Gaussian Random Projection\"\n",
    "\n",
    "    def sk(self, data):\n",
    "        X = data\n",
    "        skrfc = skSRP(n_components = 2)\n",
    "        skrfc.fit(X)\n",
    "        skrfc.transform(X)\n",
    "\n",
    "    def cuml(self, data):\n",
    "        X = data\n",
    "        cumlrfc = cumlSRP(n_components = 2)\n",
    "        cumlrfc.fit(X)\n",
    "        cumlrfc.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = BenchmarkRunner(bench_rows = [2**x for x in range(11, 25)])\n",
    "runner.run(SparseRandomProjection())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold.tsne import trustworthiness as skTrust\n",
    "from cuml.metrics. import SparseRandomProjection as cumlSRP\n",
    "\n",
    "class SparseRandomProjection(BaseAlgorithm):\n",
    "    \n",
    "    def __init__(self, load_data = load_data_mortgage_X):\n",
    "        self.name = \"gaussian_random_projection\"\n",
    "        BaseAlgorithm.__init__(self, load_data = load_data)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"Gaussian Random Projection\"\n",
    "\n",
    "    def sk(self, data):\n",
    "        X = data\n",
    "        skrfc = skSRP(n_components = 2)\n",
    "        skrfc.fit(X)\n",
    "        skrfc.transform(X)\n",
    "\n",
    "    def cuml(self, data):\n",
    "        X = data\n",
    "        cumlrfc = cumlSRP(n_components = 2)\n",
    "        cumlrfc.fit(X)\n",
    "        cumlrfc.transform(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
