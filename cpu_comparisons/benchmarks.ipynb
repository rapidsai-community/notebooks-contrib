{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark and Bounds Tests\n",
    "\n",
    "The purpose of this notebook is to benchmark all of the single GPU cuML algorithms against their skLearn counterparts, while also providing the ability to find and verify upper bounds. \n",
    "\n",
    "This benchmark will persist results into a file so that benchmarking may be continued, in the case of failure. \n",
    "\n",
    "Also supported is the ability to draw charts with the results, which should aid in presentations and transparency to end-users. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Credits\n",
    "### Authorship\n",
    "Original Author: Corey Nolet \n",
    "\n",
    "Last Edit: Corey Nolet, 03/21/2019    \n",
    "    \n",
    "### Test System Specs\n",
    "Test System Hardware: DGX-1 \n",
    "Test System Software: Ubuntu 16.04  \n",
    "RAPIDS Version: 0.6.0 - Source Install  \n",
    "Driver: 410.79  \n",
    "CUDA: 10.0  \n",
    "\n",
    "### Known Working Systems\n",
    "RAPIDS Versions: 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cudf\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 25, 10\n",
    "rcParams['figure.dpi'] = 100\n",
    "\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "\n",
    "\n",
    "import gzip\n",
    "def load_data_mortgage_X(nrows, ncols, cached = 'data/mortgage.npy.gz',source='mortgage'):\n",
    "    if os.path.exists(cached) and source=='mortgage':\n",
    "        print('use mortgage data')\n",
    "        with gzip.open(cached) as f:\n",
    "            X = np.load(f)\n",
    "        X = X[np.random.randint(0,X.shape[0]-1,nrows),:ncols]\n",
    "    else:\n",
    "        print('use random data')\n",
    "        X = np.random.random((nrows,ncols)).astype('float32')\n",
    "    df = pd.DataFrame({'fea%d'%i:X[:,i] for i in range(X.shape[1])}).fillna(0)\n",
    "    return df\n",
    "\n",
    "def load_data_mortgate_Xy(nrows, ncols, dtype = np.float32):\n",
    "    \"\"\"\n",
    "    Generate a dataframe and series based on rows and cols\n",
    "    \"\"\"\n",
    "    X = load_data_mortgage_X(nrows, ncols, dtype)\n",
    "    y = load_data_mortgage_X(nrows, 1, dtype)[\"fea0\"]\n",
    "    return (X, y)\n",
    "\n",
    "\n",
    "def load_data_X(nrows, ncols, dtype = np.float32):\n",
    "    \"\"\"\n",
    "    Generate a single dataframe with specified rows and cols\n",
    "    \"\"\"\n",
    "    X = np.random.normal(nrows,ncols)\n",
    "    df = pd.DataFrame({'fea%d'%i:X[:,i].astype(dtype) for i in range(X.shape[1])})\n",
    "    return df\n",
    "\n",
    "def load_data_Xy(nrows, ncols, dtype = np.float32):\n",
    "    \"\"\"\n",
    "    Generate a dataframe and series based on rows and cols\n",
    "    \"\"\"\n",
    "    X = load_data_X(nrows, ncols, dtype)\n",
    "    y = load_data_X(nrows, 1, dtype)[\"fea0\"]\n",
    "    return (X, y)\n",
    "\n",
    "def load_data_X_npy(nrows, ncols, dtype=np.float32):\n",
    "    return np.random.uniform(-1, 1,(nrows, ncols))\n",
    "\n",
    "def load_data_Xy_npy(nrows, ncols, dtype = np.float32):\n",
    "    X = load_data_X_npy(nrows, ncols, dtype)\n",
    "    y = load_data_X_npy(nrows, 1, dtype)\n",
    "    return (X, y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_convert(data):\n",
    "    if isinstance(data, tuple):\n",
    "        return tuple([pandas_convert(d) for d in data])\n",
    "    elif isinstance(data, pd.DataFrame):\n",
    "        return cudf.DataFrame.from_pandas(data)\n",
    "    elif isinstance(data, pd.Series):\n",
    "        return cudf.Series.from_pandas(data)\n",
    "    else:\n",
    "        raise Exception(\"Unsupported type %s\" % str(type(data)))\n",
    "        \n",
    "def no_convert(data):\n",
    "    if isinstance(data, tuple):\n",
    "        return tuple([d for d in data])\n",
    "    elif isinstance(data, np.ndarray):\n",
    "        return data\n",
    "    else:\n",
    "        raise Exception(\"Unsupported type %s\" % str(type(data)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pluggable benchmark function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeedupBenchmark(object):\n",
    "    \n",
    "    def __init__(self, converter = pandas_convert):\n",
    "        self.name = \"speedup\"\n",
    "        self.converter = converter\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"Speedup\"\n",
    "    \n",
    "    def run(self, algo, rows, dims, data):\n",
    "\n",
    "        data2 = self.converter(data)\n",
    "        cu_start = time.time()\n",
    "        algo.cuml(data2)\n",
    "        cu_elapsed = time.time() - cu_start\n",
    "        \n",
    "        sk_start = time.time()\n",
    "        algo.sk(data)\n",
    "        sk_elapsed = time.time() - float(sk_start)\n",
    "\n",
    "        # Needs to return the calculation and the name given to it.\n",
    "        return sk_elapsed / float(cu_elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BenchmarkRunner(object):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 benchmarks = [SpeedupBenchmark()],\n",
    "                 out_filename = \"benchmark.pickle\",\n",
    "                 rerun = False,\n",
    "                 n_runs = 3,\n",
    "                 bench_rows = [2**x for x in range(13, 20)],\n",
    "                 bench_dims = [64, 128, 256, 512]):\n",
    "\n",
    "        self.benchmarks = benchmarks\n",
    "        self.rerun = rerun\n",
    "        self.n_runs = n_runs\n",
    "        self.bench_rows = bench_rows\n",
    "        self.bench_dims = bench_dims\n",
    "        self.out_filename = out_filename\n",
    "        \n",
    "        \n",
    "    def load_results(self):\n",
    "        \n",
    "        if os.path.exists(self.out_filename):\n",
    "            print(\"Loaded previous benchmark results from %s\" % (self.out_filename))\n",
    "            with open(self.out_filename, 'rb') as f:\n",
    "                return pickle.load(f)\n",
    "                \n",
    "        else:\n",
    "            return {}\n",
    "        \n",
    "    def store_results(self, final_results):\n",
    "        with open(self.out_filename, 'wb') as f:\n",
    "            pickle.dump(final_results, f)\n",
    "        \n",
    "            \n",
    "    def run(self, algo):\n",
    "        \n",
    "        final_results = self.load_results()\n",
    "        \n",
    "        for benchmark in self.benchmarks:\n",
    "            if algo.name in final_results:\n",
    "                results = final_results[algo.name]\n",
    "            else:\n",
    "                results = {}\n",
    "                final_results[algo.name] = results\n",
    "\n",
    "            for n_rows in self.bench_rows:\n",
    "                for n_dims in self.bench_dims:                    \n",
    "                    if (n_rows, n_dims, benchmark.name) not in results or self.rerun:\n",
    "\n",
    "                        print(\"Running %s. (nrows=%d, n_dims=%d)\" % (str(algo), n_rows, n_dims))\n",
    "\n",
    "                        data = algo.load_data(n_rows, n_dims)\n",
    "                        runs = [benchmark.run(algo, n_rows, n_dims, data) for i in range(self.n_runs)]\n",
    "                        results[(n_rows, n_dims, benchmark.name)] = np.mean(runs)\n",
    "\n",
    "                        print(\"Benchmark for %s = %f\" % (str((n_rows, n_dims, benchmark.name)), \n",
    "                                                         results[(n_rows, n_dims, benchmark.name)]))\n",
    "                        \n",
    "                        self.store_results(final_results)\n",
    "\n",
    "                            \n",
    "    def chart(self, algo, title = \"cuML vs SKLearn\"):\n",
    "        \n",
    "        for benchmark in self.benchmarks:\n",
    "        \n",
    "            results = self.load_results()[algo.name]\n",
    "\n",
    "            final = {}\n",
    "\n",
    "            plts = []\n",
    "            for dim in self.bench_dims:\n",
    "                data = {k: v for (k, v) in results.items() if dim == k[1]}\n",
    "\n",
    "                if len(data) > 0:\n",
    "                    data = [(k[0], v) for k, v in data.items()]\n",
    "                    data.sort(key = lambda x: x[0])\n",
    "\n",
    "                    final[dim] = list(map(lambda x: x[1], data))\n",
    "\n",
    "                    keys = list(map(lambda x: np.log2(x[0]), data))\n",
    "                line = plt.plot(keys, final[dim], label = str(dim), linewidth = 3,  marker = 'o', markersize = 7)\n",
    "\n",
    "                plts.append(line[0])\n",
    "            leg = plt.legend(handles = plts, fontsize = 10)\n",
    "            leg.set_title(\"Dimensions\", prop = {'size':'x-large'})    \n",
    "            plt.title(\"%s %s: %s\" % (algo, benchmark, title), fontsize = 20)\n",
    "\n",
    "            plt.ylabel(str(benchmark), fontsize = 20)\n",
    "            plt.xlabel(\"Training Examples (2^x)\", fontsize = 20)\n",
    "\n",
    "            plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "            plt.tick_params(axis='both', which='minor', labelsize=15)\n",
    "\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseAlgorithm(object):\n",
    "    def __init__(self, load_data = load_data_X):\n",
    "        self.load_data = load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from cuml.neighbors import NearestNeighbors as cumlNN\n",
    "\n",
    "class NearestNeighborsAlgo(BaseAlgorithm):\n",
    "    \n",
    "    def __init__(self, n_neighbors = 1024, load_data = load_data_X):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.name = \"nearest_neighbors\"\n",
    "\n",
    "        BaseAlgorithm.__init__(self, load_data)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"NearestNeighbors\"\n",
    "        \n",
    "    def sk(self, X):\n",
    "        knn_sk = NearestNeighbors(n_neighbors = self.n_neighbors, algorithm = 'brute')\n",
    "        knn_sk.fit(X)\n",
    "        D_sk,I_sk = knn_sk.kneighbors(X[0:100])\n",
    "        print(\"Done SK.\")\n",
    "\n",
    "    def cuml(self, X):\n",
    "        print(\"Starting cuml\")\n",
    "        knn_cuml = cumlNN(n_neighbors = self.n_neighbors, n_gpus=5)\n",
    "        knn_cuml.fit(X)\n",
    "        print(\"Done fit.\")\n",
    "        D_cuml,I_cuml = knn_cuml.kneighbors(X[0:100])\n",
    "        print(\"Done kneighbors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = BenchmarkRunner(benchmarks = [SpeedupBenchmark(no_convert)], bench_rows = [2**x for x in range(23, 30)])\n",
    "runner.run(NearestNeighborsAlgo(load_data = load_data_X_npy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = BenchmarkRunner()\n",
    "runner.chart(NearestNeighborsAlgo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN as skDBSCAN\n",
    "from cuml import DBSCAN as cumlDBSCAN\n",
    "\n",
    "class DBSCANAlgo(BaseAlgorithm):\n",
    "    \n",
    "    def __init__(self, eps = 3, min_samples = 2):\n",
    "        self.name = \"dbscan\"\n",
    "        self.eps = 3\n",
    "        self.min_samples = 2\n",
    "        BaseAlgorithm.__init__(self)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"DBSCAN\"\n",
    "\n",
    "    def sk(self, X):\n",
    "        clustering_sk = skDBSCAN(eps = self.eps, min_samples = self.min_samples, algorithm = \"brute\")\n",
    "        clustering_sk.fit(X)\n",
    "\n",
    "    def cuml(self, X):\n",
    "        clustering_cuml = cumlDBSCAN(eps = self.eps, min_samples = self.min_samples)\n",
    "        clustering_cuml.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = BenchmarkRunner(bench_rows = [2**x for x in range(10, 17)])\n",
    "runner.run(DBSCANAlgo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = BenchmarkRunner(bench_rows = [2**x for x in range(10, 17)])\n",
    "runner.chart(DBSCANAlgo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP as skUMAP\n",
    "from cuml.manifold.umap import UMAP as cumlUMAP\n",
    "\n",
    "class UMAPAlgo(BaseAlgorithm):\n",
    "    \n",
    "    def __init__(self, n_neighbors = 5, n_epochs = 500):\n",
    "        self.name = \"umap\"\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.n_epochs = n_epochs\n",
    "        BaseAlgorithm.__init__(self)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"UMAP\"\n",
    "\n",
    "    def sk(self, X):\n",
    "        clustering_sk = skUMAP(n_neighbors = self.n_neighbors, n_epochs = self.n_epochs)\n",
    "        clustering_sk.fit(X)\n",
    "\n",
    "    def cuml(self, X):\n",
    "        clustering_cuml = cumlUMAP(n_neighbors = self.n_neighbors, n_epochs = self.n_epochs)\n",
    "        clustering_cuml.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = BenchmarkRunner(rerun = True, bench_rows = [2**x for x in range(10, 20)])\n",
    "runner.run(UMAPAlgo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = BenchmarkRunner(bench_rows = [2**x for x in range(10, 15)])\n",
    "runner.chart(UMAPAlgo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = BenchmarkRunner().load_results()\n",
    "\n",
    "l = []\n",
    "for k in runner[\"umap\"]:\n",
    "    if k[0] > 32768:\n",
    "        l.append(k)\n",
    "        \n",
    "for i in l:\n",
    "    del runner[\"umap\"][i]\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BenchmarkRunner().store_results(runner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression as skLR\n",
    "from cuml.linear_model import LinearRegression as cumlLR\n",
    "\n",
    "class LinearRegressionAlgo(BaseAlgorithm):\n",
    "    def __init__(self):\n",
    "        BaseAlgorithm.__init__(self, load_data_Xy)\n",
    "        self.name = \"linear_regression\"\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"Linear Regression\"\n",
    "\n",
    "    def sk(self, data):\n",
    "        X, y = data\n",
    "        clustering_sk = skLR()\n",
    "        clustering_sk.fit(X, y)\n",
    "\n",
    "    def cuml(self, data):\n",
    "        X, y = data\n",
    "        cuml_lr = cumlLR()\n",
    "        cuml_lr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = BenchmarkRunner(rerun = True, bench_rows = [2**x for x in range(15, 23)]).run(LinearRegressionAlgo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = BenchmarkRunner(bench_rows = [2**x for x in range(10, 17)])\n",
    "runner.chart(LinearRegressionAlgo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA / SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA as skPCA\n",
    "from cuml import PCA as cumlPCA\n",
    "\n",
    "class PCAAlgo(BaseAlgorithm):\n",
    "    \n",
    "    def __init__(self, n_components = 10, load_data = load_data_mortgage_X):\n",
    "        self.n_components = 10\n",
    "        self.name = \"pca\"\n",
    "        BaseAlgorithm.__init__(self, load_data = load_data)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"PCA\"\n",
    "\n",
    "    def sk(self, X):\n",
    "        skpca = skPCA(n_components = 10)\n",
    "        skpca.fit(X)\n",
    "\n",
    "    def cuml(self, X):\n",
    "        cumlpca = cumlPCA(n_components = 10)\n",
    "        cumlpca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = BenchmarkRunner(bench_rows = [2**x for x in range(18, 23)])\n",
    "runner.run(PCAAlgo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = BenchmarkRunner(bench_rows = [2**x for x in range(10, 17)])\n",
    "runner.chart(LinearRegressionAlgo())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cuml3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
