{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAPIDS Customized Kernel Tutorial\n",
    "\n",
    "### RAPIDS overview\n",
    "\n",
    "The RAPIDS suite of software libraries, built on CUDA-X AI, gives you the freedom to execute end-to-end data science and analytics pipelines entirely on GPUs. \n",
    "\n",
    "![RAPIDS components](https://rapids.ai/assets/images/Pipeline-FPO-Diagram.png)\n",
    "\n",
    "`cuDF` is the library that is similar to `Pandas` library. It accelerates the Dataframe operations in the GPU. `cuDF` is an on going project that a lot of important dataframe functions are missinng. One solution is to build customized GPU kernels to implement them.\n",
    "\n",
    "This tutorial will show how to do this with different methods ordered by implmentation difficulties. It is organized as:\n",
    "\n",
    "1. Customized Kernel by RAPIDS API\n",
    "2. Customized Kernel by NUMBA library\n",
    "3. Customized Kernel by CuPy library\n",
    "4. Summary \n",
    "\n",
    "### Toy Problem, compute the distance of points to the origin\n",
    "\n",
    "The toy problem is to compute the distance of the list of points in 2-D space to the origin. First generate 1000 random points and load them to the GPU dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import cudf\n",
    "import numpy as np\n",
    "import math\n",
    "from numba import cuda\n",
    "import cupy\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# construct the dataframe to store x and y coordinates of the points\n",
    "df = cudf.DataFrame()\n",
    "df['x'] = np.random.rand(1000)\n",
    "df['y'] = np.random.rand(1000)\n",
    "# visualize the points\n",
    "plt.figure()\n",
    "plt.scatter(df['x'], df['y'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the ground truth distance by RAPIDS calls. And define the validation function to make sure the result matchs the ground truth for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ground_truth'] = cudf.sqrt(df['x']**2 + df['y']**2)\n",
    "# function to verify the results\n",
    "def verify(ground_truth, computed):\n",
    "    max_difference = cudf.sqrt((ground_truth - computed)**2).max()\n",
    "    assert(max_difference < 1e-8)\n",
    "    return max_difference\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customized Kernel by RAPIDS API\n",
    "\n",
    "This is the easiest way to customize your computations.\n",
    "\n",
    "Introduce two functions:\n",
    "* apply_rows\n",
    "* apply_chunks\n",
    "\n",
    "`apply_rows` processes each of the rows of the Dataframe independently in parallel. Under the hood, the `apply_rows` method will optimally divide the long columns into chunks, and assign chunks into different GPU blocks and threads to compute. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use `apply_rows`, start with a simple Python function to compute the distance. `apply_rows` uses `Numba` to compile it to GPU native code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_fun(x, y, distance):\n",
    "    for i, (x_value, y_value) in enumerate(zip(x, y)):\n",
    "        print('tid:', cuda.threadIdx.x, 'bid:', cuda.blockIdx.x, 'array size:', x.size, 'block threads:', cuda.blockDim.x, 'i', i )\n",
    "        distance[i] = math.sqrt(x_value**2 + y_value**2)\n",
    "\n",
    "outdf = df.apply_rows(distance_fun,\n",
    "                      incols=['x', 'y'],\n",
    "                      outcols=dict(distance=np.float64),\n",
    "                      kwargs=dict())\n",
    "\n",
    "error = verify(outdf['ground_truth'], outdf['distance']) \n",
    "error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the example output from console for `apply_rows` call\n",
    "```\n",
    "...\n",
    "tid: 27 bid: 11 array size: 1 block threads: 64 i 0\n",
    "tid: 28 bid: 11 array size: 1 block threads: 64 i 0\n",
    "tid: 29 bid: 11 array size: 1 block threads: 64 i 0\n",
    "tid: 30 bid: 11 array size: 1 block threads: 64 i 0\n",
    "tid: 31 bid: 11 array size: 1 block threads: 64 i 0\n",
    "tid: 32 bid: 0 array size: 2 block threads: 64 i 1\n",
    "tid: 33 bid: 0 array size: 2 block threads: 64 i 1\n",
    "tid: 34 bid: 0 array size: 2 block threads: 64 i 1\n",
    "tid: 35 bid: 0 array size: 2 block threads: 64 i 1\n",
    "tid: 36 bid: 0 array size: 2 block threads: 64 i 1\n",
    "tid: 37 bid: 0 array size: 2 block threads: 64 i 1\n",
    "...\n",
    "```\n",
    "It uses 15 CUDA blocks (0 indexed). Each CUDA block uses 64 threads to do the computation. Each of the threads is handling an array of length 1 or 2. The row element processing order is not defined. \n",
    "\n",
    "`apply_chunks` has more control than `apply_rows`.  It can specify how to divide the long array into chunks, map each of the array chunks to different GPU blocks to process (chunks argument) and assign the number of thread in the block (tpb argument).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_fun(x, y, distance):\n",
    "    print('tid:', cuda.threadIdx.x, 'bid:', cuda.blockIdx.x, 'array size:', x.size, 'block threads:', cuda.blockDim.x, 'grid dim', cuda.gridDim.x)\n",
    "    for i in range(cuda.threadIdx.x, x.size, cuda.blockDim.x):\n",
    "        distance[i] = math.sqrt(x[i]**2 + y[i]**2)\n",
    "\n",
    "outdf2 = df.apply_chunks(distance_fun,\n",
    "                      incols=['x', 'y'],\n",
    "                      outcols=dict(distance=np.float64),\n",
    "                      kwargs=dict(),\n",
    "                      chunks=32,\n",
    "                      tpb=16)\n",
    "\n",
    "error = verify(outdf2['ground_truth'], outdf2['distance']) \n",
    "error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the example output from console for `apply_chunks` call\n",
    "```\n",
    "...\n",
    "tid: 12 bid: 12 array size: 32 block threads: 16 grid dim 16\n",
    "tid: 13 bid: 12 array size: 32 block threads: 16 grid dim 16\n",
    "tid: 14 bid: 12 array size: 32 block threads: 16 grid dim 16\n",
    "tid: 15 bid: 12 array size: 32 block threads: 16 grid dim 16\n",
    "tid: 0 bid: 7 array size: 32 block threads: 16 grid dim 16\n",
    "tid: 1 bid: 7 array size: 32 block threads: 16 grid dim 16\n",
    "tid: 2 bid: 7 array size: 32 block threads: 16 grid dim 16\n",
    "tid: 3 bid: 7 array size: 32 block threads: 16 grid dim 16\n",
    "tid: 4 bid: 7 array size: 32 block threads: 16 grid dim 16\n",
    "...\n",
    "```\n",
    "The kernel `distance_fun` is invoked concurrently on each specified chunk. It has full access to all the elements in that chunk of the array. \n",
    "\n",
    "In this example, it cuts the 1000 elements into chunks of size 32 (except the last one) and assigns them to 16 blocks.\n",
    "\n",
    "Each block uses 16 threads to process its array of size 32."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customized Kernel by Numba library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`apply_rows` and `apply_chunks` methods in cuDF use `Numba` library to compile the normal python code into GPU kernels under the hood. \n",
    "\n",
    "`Numba` is an excellent python library that accelerates the numerical computations. \n",
    "\n",
    "Most importantly, `Numba` supports CUDA GPU programming by directly compiling a restricted subset of Python code into CUDA kernels and device functions following the CUDA execution model.\n",
    "\n",
    "`cuDF` series can be converted to GPU arrays that the `Numba` library recognizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df['x'].data.to_gpu_array())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Numba` GPU kernel is written in Python and translated into GPU code in the runtime. We just need to decorate the Python function with `@cuda.jit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def distance_kernel(x, y, distance, array_len):\n",
    "    i = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n",
    "    if i < array_len:\n",
    "        distance[i] = math.sqrt(x[i]**2 + y[i]**2)\n",
    "\n",
    "number_of_threads = 16\n",
    "number_of_blocks = (len(df) -1)//number_of_threads + 1\n",
    "df['distance_numba'] = 0.0\n",
    "distance_kernel[(number_of_blocks,), (number_of_threads,)](df['x'].data.to_gpu_array(), df['y'].data.to_gpu_array(), df['distance_numba'].data.to_gpu_array(), len(df))\n",
    "error = verify(df['ground_truth'], df['distance_numba']) \n",
    "error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice this Python kernel function is very similar to the CUDA kernel functions. All the input GPU arrays are in the GPU global memory. They are accessible for all the threads in the kernel. With simple modification, we can compute the distance difference for consecutive points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def distance_diff_kernel(x, y, distance, array_len):\n",
    "    i = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n",
    "    if i < array_len and i > 0:\n",
    "        distance[i] = math.sqrt(x[i]**2 + y[i]**2) - math.sqrt(x[i-1]**2 + y[i-1]**2)\n",
    "\n",
    "number_of_threads = 16\n",
    "number_of_blocks = (len(df) -1)//number_of_threads + 1\n",
    "df['distance_diff'] = 0.0\n",
    "distance_diff_kernel[(number_of_blocks,), (number_of_threads,)](df['x'].data.to_gpu_array(), df['y'].data.to_gpu_array(), df['distance_diff'].data.to_gpu_array(), len(df))\n",
    "df.to_pandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, only a subset of the CUDA functions are supported in the `Numba` kernels. Advanced functions like device function recursion, objects ... are not supported. Check the [Numba documents](https://numba.pydata.org/numba-doc/dev/cuda/index.html) for details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customized Kernel by CuPy library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Numba` is to compile the Python code into GPU code in the runtime. It has some limitations to use it. And it adds some overhead using it too. \n",
    "When the Python process calls the `Numba` kernel for the first time, it take some CPU time to compile the Python code.\n",
    "\n",
    "If advanced feature is needed and lattency is important, `CuPy` can be used to compile raw C/C++ CUDA code.\n",
    "\n",
    "First `cuDf` data need to be changed into `CuPy` arrays. This can be done via `dlpack`. `DLPack` is an open in-memory tensor structure to for sharing tensor among frameworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the data from cudf to cupy\n",
    "dl_pack = df[['x', 'y']].to_dlpack()\n",
    "o = cupy.fromDlpack(dl_pack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`CuPy` kernel is raw C/C++ CUDA code that is compiled statically and cached in the filesystem. So compilation overhead only happens once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_kernel = cupy.RawKernel(r'''\n",
    "    extern \"C\" __global__\n",
    "    void compute_distance(const double* x, const double* y, double* distance, int arr_len) {\n",
    "        int tid = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "        if (tid < arr_len){\n",
    "        distance[tid] = sqrt(x[tid]*x[tid] + y[tid]*y[tid]);\n",
    "        }\n",
    "    }\n",
    "''', 'compute_distance')\n",
    "number_of_threads = 16\n",
    "number_of_blocks = (len(df) -1)//number_of_threads + 1\n",
    "\n",
    "# output cupy array\n",
    "dis = cupy.arange(len(df), dtype=cupy.float64)\n",
    "raw_kernel((number_of_blocks,), (number_of_threads,), (o[:, 0], o[:, 1], dis, len(o))) \n",
    "df['distance_cupy'] = dis\n",
    "error = verify(df['ground_truth'], df['distance_cupy']) \n",
    "error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nearly all the advanced CUDA features are available inside the `RawKernel` of `CuPy` library. It is the most powerful way of using GPU but requires good knowledge about CUDA development. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "We have shown 3 methods to implement customized kernels in Python. In summary, following is a comparison table:\n",
    "\n",
    "Methods | Development Difficulty  | Flexibility | Efficiency | Lattency\n",
    "--- | --- | --- | --- | --- |\n",
    "API method | easy | low | low | high |\n",
    "`Numba` method | medium | medium | low | high |\n",
    "`CuPy` method | hard | high | high | low |\n",
    "\n",
    "Choose the right approach to balance the efficieny, difficulty and flexibility.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
