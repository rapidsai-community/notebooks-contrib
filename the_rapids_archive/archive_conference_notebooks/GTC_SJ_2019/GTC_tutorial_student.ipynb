{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cuml\n",
    "import cudf\n",
    "import nvcategory\n",
    "\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "data_dir = '../../data/blackfriday/'\n",
    "if not os.path.exists(data_dir):\n",
    "    print('creating black friday data directory')\n",
    "    os.system('mkdir ../../data/blackfriday')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://datahack-prod.s3.amazonaws.com/train_zip/'\n",
    "ofn = 'train_oSwQCTC.zip'\n",
    "fn = 'train.zip'\n",
    "if not os.path.isfile(data_dir+ofn):\n",
    "        print(f'Downloading {base_url+ofn} to {data_dir+fn}')\n",
    "        urllib.request.urlretrieve(base_url+ofn, data_dir+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the data. Notice how it decompresses as it reads the data into memory. \n",
    "gdf = cudf.read_csv(data_dir+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking a look at the data. We use \"to_pandas()\" to get the pretty printing. \n",
    "gdf.head().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise: Let's do some descriptive statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hint: try some of the function you may know from Pandas like DataFrame.Series.max() or look up the documentation here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grabbing the first character of the years in city string to get rid of plus sign, and converting to int\n",
    "gdf['city_years'] = gdf.Stay_In_Current_City_Years.str.get(0).stoi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we can see how we can control what the value of our dummies with the replace method and turn strings to ints\n",
    "gdf['City_Category'] = gdf.City_Category.str.replace('A', '1')\n",
    "gdf['City_Category'] = gdf.City_Category.str.replace('B', '2')\n",
    "gdf['City_Category'] = gdf.City_Category.str.replace('C', '3')\n",
    "gdf['City_Category'] = gdf['City_Category'].str.stoi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXERCISE: replace city in the same way as City Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hint: the Gender column only has values 'M' and 'F'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's take a look at how many products we have\n",
    "prod_count = cudf.Series(nvcategory.from_strings(gdf.Product_ID.data).values()).unique().count() #hideous one-liner\n",
    "print(\"Unique Products: {}\".format(prod_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's take a look at how many primary product categories we have\n",
    "#We do it differently here because the variable is a number, not a string\n",
    "prod1_count = gdf.Product_Category_1.unique().count()\n",
    "print(\"Unique Product Categories: {}\".format(prod1_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling missing values\n",
    "gdf['Product_Category_2'] = gdf['Product_Category_2'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXERCISE: Make a variable that's 1 if the product is multi-category, 0 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hint: think about how to combine the Product Category 2 and Product Category 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solution: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXERCISE: Create a Gender/Marital Status Interaction Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hint: bother Gender and Marital Status are 0/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solution:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Because Occupation is a code, it should converted into indicator variables\n",
    "gdf = gdf.one_hot_encoding('Occupation', 'occ_dummy', gdf.Occupation.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dummy variable from Int\n",
    "gdf = gdf.one_hot_encoding('City_Category', 'city_cat', gdf.City_Category.unique())\n",
    "\n",
    "#Dummy from string\n",
    "cat = nvcategory.from_strings(gdf.Age.data)\n",
    "gdf['Age'] = cudf.Series(cat.values())\n",
    "gdf = gdf.one_hot_encoding('Age', 'age', gdf.Age.unique())\n",
    "\n",
    "#EXERCISE: Create dummy variables from Product Category 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solution:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We're going to drop th variables we've transformed\n",
    "drop_list = ['User_ID', 'Age', 'Stay_In_Current_City_Years', 'City_Category','Product_ID', 'Product_Category_1', 'Product_Category_2', 'Product_Category_3']\n",
    "gdf = gdf.drop(drop_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We're going to make a list of all the first indicator variables in a series now so it will be\n",
    "#easier to exclude them when we're doing regressions later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_list = ['occ_dummy_0', 'city_cat_1', 'age_0', 'product_1', 'Purchase']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All variables currently have to have the same type for some methods in cuML\n",
    "for col in gdf.columns.tolist():\n",
    "    gdf[col] = gdf[col].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = round(len(gdf)*0.8)\n",
    "test_size = round(len(gdf)-train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = gdf.iloc[0:train_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXERCISE: Make the test set in a similar way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solution:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleting the main gdf because we're going to be making other subsets and other stuff, so it will be nice to have the memory. \n",
    "del(gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = gdf_train['Purchase']\n",
    "X_reg = gdf_train.drop(dummy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # I'm going to perform a hyperparameter search for alpha in a ridge regression\n",
    "# for alpha in np.arange(0.0, 1, 0.01):\n",
    "    \n",
    "#     Ridge = cuml.Ridge(alpha=alpha, fit_intercept=True)\n",
    "#     _fit = Ridge.fit(X_reg, y_train)\n",
    "#     _y_hat = _fit.predict(X_reg)\n",
    "#     _roc = roc_auc_score(y_train, _y_hat)\n",
    "#     output['MSE_RIDGE_{}'.format(alpha)] = _roc\n",
    "\n",
    "# print('MAX AUC: {}'.format(min(output, key=output.get)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge = cuml.Ridge(alpha=.1, fit_intercept=True)\n",
    "# _fit = Ridge.fit(X_reg, y_train)\n",
    "# _y_hat = _fit.predict(X_reg)\n",
    "# _roc = roc_auc_score(y_train, _y_hat)\n",
    "# output['MSE_RIDGE_{}'.format(alpha)] = _roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_xgb = gdf_train[['Purchase']]\n",
    "# X_xgb = gdf_train.drop('Purchase')\n",
    "# xgb_train_set = xgb.DMatrix(data=X_xgb, label=y_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_params = {\n",
    "#     'nround':100,\n",
    "#     'max_depth':4,\n",
    "#     'max_leaves':2**4,\n",
    "#     'tree_method':'gpu_hist',\n",
    "#     'n_gpus':1,\n",
    "#     'loss':'ls',\n",
    "#     'objective':'reg:linear',\n",
    "#     'max_features':'auto',\n",
    "#     'criterion':'friedman_mse',\n",
    "#     'grow_policy':'lossguide',\n",
    "#     'verbose':True\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_model = xgb.train(xgb_params, dtrain=xgb_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_hat_xgb = xgb_model.predict(xgb_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE = np.sqrt(mean_squared_error(y_xgb['Purchase'].to_pandas(), y_hat_xgb)) #get out of sample RMSE too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXERCISE: Change XGB around to predict if someone is married based on the data we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hint: in the xgb parameters, change the objective function to 'reg:logistic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solution\n",
    "# y_xgb = gdf_train[['Marital_Status']]\n",
    "# X_xgb = gdf_train.drop('Marital_Status')\n",
    "# xgb_train_set = xgb.DMatrix(data=X_xgb, label=y_xgb)\n",
    "\n",
    "# xgb_params = {\n",
    "#     'nround':100,\n",
    "#     'max_depth':4,\n",
    "#     'max_leaves':2**4,\n",
    "#     'tree_method':'gpu_hist',\n",
    "#     'n_gpus':1,\n",
    "#     'loss':'ls',\n",
    "#     'objective':'reg:logistic',\n",
    "#     'max_features':'auto',\n",
    "#     'criterion':'friedman_mse',\n",
    "#     'grow_policy':'lossguide',\n",
    "#     'verbose':True\n",
    "# }\n",
    "\n",
    "# xgb_model = xgb.train(xgb_params, dtrain=xgb_train_set)\n",
    "# y_hat_xgb = xgb_model.predict(xgb_train_set)\n",
    "# AUC = roc_auc_score(y_xgb['Marital_Status'].to_pandas(), y_hat_xgb)\n",
    "# print(AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXTRA EXERCISE: Apply kNN to the customers\n",
    "#EXTRA EXERCISE: Apply PCA to data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
