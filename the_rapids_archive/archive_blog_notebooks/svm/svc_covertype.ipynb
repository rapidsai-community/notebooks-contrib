{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Classification using RAPIDS cuML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use cuML SVM on the forest cover type dataset and measures its performance compared to scikit-learn SVM and ThunderSVM. This notebook provides supplementary information for the Benchmark section of the [RAPIDS cuML SVC](https://nvda.ws/3c3Qy8H) blog post.\n",
    "\n",
    "We also have have simpler [notebook](https://github.com/rapidsai/cuml/blob/branch-0.13/notebooks/svm_demo.ipynb) on how to use cuML SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cuml\n",
    "import numpy as np\n",
    "import sklearn.svm\n",
    "\n",
    "from cudf import Series\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.datasets import fetch_covtype\n",
    "from sklearn.model_selection import train_test_split\n",
    "from timeit import default_timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the measurements in the blog, we compiled [ThunderSVM](https://github.com/Xtra-Computing/thundersvm) from source (this [version](https://github.com/Xtra-Computing/thundersvm/tree/f604b42e15012d164cdf5ee14b528ab94d535b91)). You can also [search PyPI](https://pypi.org/search/?q=thundersvm) for a package that matches your CUDA version and pip install that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install thundersvm-cuda10\n",
    "try:\n",
    "    import thundersvm\n",
    "    thundersvm_loaded = True\n",
    "except ImportError:\n",
    "    thundersvm_loaded = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset\n",
    "We use the [covertype](https://archive.ics.uci.edu/ml/datasets/covertype) dataset. We do the following processing steps:\n",
    "- We transform it to binary classification (class 2 or not).\n",
    "- Scale the first 10 columns. The rest are binary input, we leave it unchanged.\n",
    "- Split the data: use 90% of the samples for training, and 10% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_covtype(data_home='/mydata/blog/scikit_learn_data', return_X_y=True)\n",
    "\n",
    "y = (y==2).astype(np.float32) # Make it into bynary classification\n",
    "\n",
    "X[:,0:10] = sklearn.preprocessing.StandardScaler().fit_transform(X[:,0:10])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=77, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and predict with cuML SVC\n",
    "We define the an SVC classifier using radial basis function ('rbf') kernel with gamma=1, and 2G kernel cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = cuml.svm.SVC(kernel='rbf', C=10, gamma=1, cache_size=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The warning message about column major data layout can be ignored.\n",
    "\n",
    "### Make prediction and check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svc.predict(X_test)\n",
    "cuml.metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark SVC classifiers\n",
    "The actual training time depends on the dataset and the model parameters. The penalty parameter (C) has a particularly strong effect on it. Theoretically, the training time for an SVM is around O(N^2) for small C and closer to O(N^3) for large C, where N is the number of training vectors. The example that we show here scales quadratically. Because of this, it would take very long to fit the whole dataset using the CPU. Instead we measure the execution time on several subset of the data.\n",
    "\n",
    "### Prepare data\n",
    "While cuML use only dense input, ThunderSVM and scikit-learn SVM runs more efficiently on this dataset using a sparse representation. Therefore we transform the dataset to sparse format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = csr_matrix(X_train.astype(np.float32))\n",
    "X_test = csr_matrix(X_test.astype(np.float32))\n",
    "print('Fraction of nonzeros {:4.1f} %'.format(X_train.nnz / np.prod(X_train.shape)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper routines for to benchmark SVM classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_svm(clf, X_train, X_test, y_train, y_test):\n",
    "    \"\"\" Helper script to measue time to fit and predict a classifier .\n",
    "    \n",
    "    Parameters:\n",
    "    clf - initialized classifier\n",
    "    X_train - feature vectors for training\n",
    "    X_test - feature vectors for testing\n",
    "    y_train - train labels\n",
    "    y_test - test labels\n",
    "    \n",
    "    Retruns a list of four values [m, t_fit, t_pred, acc]:\n",
    "    m - number of training vectors\n",
    "    t_fit - time to train in seconds\n",
    "    t_pred - time to predict in seconds\n",
    "    acc - accuracy score\n",
    "    \"\"\"\n",
    "    \n",
    "    # Measure time to fit\n",
    "    start = default_timer()\n",
    "    clf.fit(X_train, y_train)\n",
    "    stop = default_timer()\n",
    "    t_fit = stop - start\n",
    "    \n",
    "    # Measure time to predict\n",
    "    start = default_timer()\n",
    "    clf.predict(X_train)\n",
    "    stop = default_timer()\n",
    "    t_pred = stop - start\n",
    "        \n",
    "    # Calculate accuracy\n",
    "    y_pred = clf.predict(X_test)\n",
    "    if isinstance(y_pred, Series):\n",
    "        acc = cuml.metrics.accuracy_score(y_test, y_pred)\n",
    "    else: \n",
    "        acc = sklearn.metrics.accuracy_score(y_test, y_pred)\n",
    "        \n",
    "    return [X_train.shape[0], t_fit, t_pred, acc]\n",
    "\n",
    "def cuml_time_svm(X_train, X_test, y_train, y_test, params):\n",
    "    clf = cuml.svm.SVC(**params)\n",
    "    if isinstance (X_train, csr_matrix):\n",
    "        # cuML needs dense inputs matrices\n",
    "        X_train = X_train.toarray()\n",
    "        X_test = X_test.toarray()\n",
    "    return time_svm(clf, X_train, X_test, y_train, y_test)    \n",
    "\n",
    "def skl_time_svm(X_train, X_test, y_train, y_test, params):\n",
    "    if X_train.shape[0] <= 50000: # cut-off for Sklearn training\n",
    "        clf = sklearn.svm.SVC(**params)\n",
    "        return time_svm(clf, X_train, X_test, y_train, y_test)\n",
    "    else:\n",
    "        return [X_train.shape[0], np.nan, np.nan, np.nan]\n",
    "    \n",
    "def thunder_time_svm(X_train, X_test, y_train, y_test, params):\n",
    "    thu_params = dict(params)\n",
    "    if thu_params['kernel']=='poly':\n",
    "        thu_params['kernel'] = 'polynomial'\n",
    "    clf = thundersvm.SVC(**thu_params)\n",
    "    return time_svm(clf, X_train, X_test, y_train, y_test)\n",
    "\n",
    "def run_benchmark(X_train, X_test, y_train, y_test, m_list, params, run_skl=True, run_thunder=True, run_cuml=True):\n",
    "    # We store the benchmark results in matrices with four columns: m, t_fit, t_pred, accuracy\n",
    "    res_skl = np.zeros((len(m_list),4)) \n",
    "    res_cuml = np.zeros((len(m_list),4)) \n",
    "    res_thunder = np.zeros((len(m_list),4))\n",
    "        \n",
    "    i = 0\n",
    "    for m in m_list:\n",
    "        X_in = X_train[:m,:]\n",
    "        y_in = y_train[:m]\n",
    "\n",
    "        if run_cuml:            \n",
    "            res_cuml[i,:] = cuml_time_svm(X_in, X_test, y_in, y_test, params)\n",
    "            print('cuML    time for traning size {:6} is {:4.2f} sec, accuracy {:%}'.format(m, res_cuml[i,1], res_cuml[i,3]))\n",
    "            \n",
    "        if run_skl:\n",
    "            res_skl[i,:] = skl_time_svm(X_in, X_test, y_in, y_test, params)\n",
    "            print('Skl     time for traning size {:6} is {:4.2f} sec, accuracy {:%}'.format(m, res_skl[i,1], res_skl[i,3]))\n",
    "            \n",
    "        if run_thunder:\n",
    "            res_thunder[i,:] = thunder_time_svm(X_in, X_test, y_in, y_test, params)\n",
    "            print('Thunder time for traning size {:6} is {:4.2f} sec, accuracy {:%}'.format(m, res_thunder[i,1], res_thunder[i,3]))\n",
    "        i += 1      \n",
    "\n",
    "    return res_cuml, res_skl, res_thunder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define SVC parameters\n",
    "We will use the same parameters as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'kernel':'rbf', 'C':1, 'gamma': 1, 'cache_size':2000}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start with a warmup\n",
    "_ = run_benchmark(X_train, X_test, y_train, y_test, [10, 100], params, run_thunder=thundersvm_loaded)\n",
    "\n",
    "# Run the benchmark\n",
    "m_list = [10, 100, 1000, 10000, 50000, 100000, 200000, 300000, 400000, X_train.shape[0]]\n",
    "res_cuml, res_skl, res_thunder = run_benchmark(X_train, X_test, y_train, y_test, m_list, params, run_thunder=thundersvm_loaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15,4))\n",
    "ax = fig.add_subplot(131)\n",
    "ax.plot(res_skl[:,0], res_skl[:,1], 'o-', label='scikit-learn')\n",
    "ax.plot(res_thunder[:,0], res_thunder[:,1], 's-', label='ThunderSVM ')\n",
    "ax.plot(res_cuml[:,0], res_cuml[:,1], '>-', label='cuML')\n",
    "   \n",
    "ax.set_xlabel('n_samples')\n",
    "ax.set_ylabel('train time (s)')\n",
    "ax.legend()\n",
    "ax.set_title('time to train')\n",
    "\n",
    "ax = fig.add_subplot(132)\n",
    "ax.plot(res_skl[:,0], res_skl[:,2], 'o-', label='scikit-learn')\n",
    "ax.plot(res_thunder[:,0], res_thunder[:,2], 's-', label='ThunderSVM')\n",
    "ax.plot(res_cuml[:,0], res_cuml[:,2], '>-', label='cuML SVM')\n",
    "ax.set_xlabel('n_samples')\n",
    "ax.set_ylabel('train predict (s)')\n",
    "ax.legend()\n",
    "ax.set_title('time to predict')\n",
    "\n",
    "ax = fig.add_subplot(133)\n",
    "ax.plot(res_skl[:,0], res_skl[:,3]*100, 'o-', label='scikit-learn')\n",
    "ax.plot(res_thunder[:,0], res_thunder[:,3]*100, '*-', label='ThunderSVM')\n",
    "ax.plot(res_cuml[:,0], res_cuml[:,3]*100, '>-', label='cuML SVM')\n",
    "ax.set_xlabel('n_samples')\n",
    "ax.set_ylabel('accuracy %')\n",
    "ax.legend()\n",
    "ax.set_title('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
